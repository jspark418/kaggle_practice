{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-12-29T07:42:56.667527Z","iopub.status.busy":"2021-12-29T07:42:56.667204Z","iopub.status.idle":"2021-12-29T07:42:56.685684Z","shell.execute_reply":"2021-12-29T07:42:56.684978Z","shell.execute_reply.started":"2021-12-29T07:42:56.667498Z"},"trusted":true},"outputs":[],"source":["# 아래 사이트 필사\n","# Start Here: A Gentle Introduction (https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction)\n","\n","\n","# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:42:56.687489Z","iopub.status.busy":"2021-12-29T07:42:56.687236Z","iopub.status.idle":"2021-12-29T07:42:56.702133Z","shell.execute_reply":"2021-12-29T07:42:56.700964Z","shell.execute_reply.started":"2021-12-29T07:42:56.687458Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","import os\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:42:56.704795Z","iopub.status.busy":"2021-12-29T07:42:56.704071Z","iopub.status.idle":"2021-12-29T07:42:56.717739Z","shell.execute_reply":"2021-12-29T07:42:56.717219Z","shell.execute_reply.started":"2021-12-29T07:42:56.704752Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['data', 'home-credit-default-risk.ipynb']\n"]}],"source":["print(os.listdir('./'))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:42:56.719543Z","iopub.status.busy":"2021-12-29T07:42:56.718721Z","iopub.status.idle":"2021-12-29T07:43:01.721002Z","shell.execute_reply":"2021-12-29T07:43:01.720492Z","shell.execute_reply.started":"2021-12-29T07:42:56.719510Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(307511, 122)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv('./data/application_train.csv')\n","test = pd.read_csv('./data/application_test.csv')\n","train.shape"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:01.723854Z","iopub.status.busy":"2021-12-29T07:43:01.722845Z","iopub.status.idle":"2021-12-29T07:43:01.748916Z","shell.execute_reply":"2021-12-29T07:43:01.748001Z","shell.execute_reply.started":"2021-12-29T07:43:01.723783Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SK_ID_CURR</th>\n","      <th>TARGET</th>\n","      <th>NAME_CONTRACT_TYPE</th>\n","      <th>CODE_GENDER</th>\n","      <th>FLAG_OWN_CAR</th>\n","      <th>FLAG_OWN_REALTY</th>\n","      <th>CNT_CHILDREN</th>\n","      <th>AMT_INCOME_TOTAL</th>\n","      <th>AMT_CREDIT</th>\n","      <th>AMT_ANNUITY</th>\n","      <th>...</th>\n","      <th>FLAG_DOCUMENT_18</th>\n","      <th>FLAG_DOCUMENT_19</th>\n","      <th>FLAG_DOCUMENT_20</th>\n","      <th>FLAG_DOCUMENT_21</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>100002</td>\n","      <td>1</td>\n","      <td>Cash loans</td>\n","      <td>M</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>202500.0</td>\n","      <td>406597.5</td>\n","      <td>24700.5</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>100003</td>\n","      <td>0</td>\n","      <td>Cash loans</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>0</td>\n","      <td>270000.0</td>\n","      <td>1293502.5</td>\n","      <td>35698.5</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>100004</td>\n","      <td>0</td>\n","      <td>Revolving loans</td>\n","      <td>M</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>67500.0</td>\n","      <td>135000.0</td>\n","      <td>6750.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>100006</td>\n","      <td>0</td>\n","      <td>Cash loans</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>135000.0</td>\n","      <td>312682.5</td>\n","      <td>29686.5</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>100007</td>\n","      <td>0</td>\n","      <td>Cash loans</td>\n","      <td>M</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>121500.0</td>\n","      <td>513000.0</td>\n","      <td>21865.5</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 122 columns</p>\n","</div>"],"text/plain":["   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n","0      100002       1         Cash loans           M            N   \n","1      100003       0         Cash loans           F            N   \n","2      100004       0    Revolving loans           M            Y   \n","3      100006       0         Cash loans           F            N   \n","4      100007       0         Cash loans           M            N   \n","\n","  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n","0               Y             0          202500.0    406597.5      24700.5   \n","1               N             0          270000.0   1293502.5      35698.5   \n","2               Y             0           67500.0    135000.0       6750.0   \n","3               Y             0          135000.0    312682.5      29686.5   \n","4               Y             0          121500.0    513000.0      21865.5   \n","\n","   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n","0  ...                 0                0                0                0   \n","1  ...                 0                0                0                0   \n","2  ...                 0                0                0                0   \n","3  ...                 0                0                0                0   \n","4  ...                 0                0                0                0   \n","\n","  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n","0                        0.0                       0.0   \n","1                        0.0                       0.0   \n","2                        0.0                       0.0   \n","3                        NaN                       NaN   \n","4                        0.0                       0.0   \n","\n","   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n","0                         0.0                        0.0   \n","1                         0.0                        0.0   \n","2                         0.0                        0.0   \n","3                         NaN                        NaN   \n","4                         0.0                        0.0   \n","\n","   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n","0                        0.0                         1.0  \n","1                        0.0                         0.0  \n","2                        0.0                         0.0  \n","3                        NaN                         NaN  \n","4                        0.0                         0.0  \n","\n","[5 rows x 122 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Exploratory Data Analysis¶\n"]},{"cell_type":"markdown","metadata":{},"source":["## Examine the Distribution of the Target Column\n","The target is what we are asked to predict: either a 0 for the loan was repaid on time, or a 1 indicating the client had payment difficulties. We can first examine the number of loans falling into each category."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:01.750341Z","iopub.status.busy":"2021-12-29T07:43:01.750095Z","iopub.status.idle":"2021-12-29T07:43:01.773204Z","shell.execute_reply":"2021-12-29T07:43:01.772341Z","shell.execute_reply.started":"2021-12-29T07:43:01.750282Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0    282686\n","1     24825\n","Name: TARGET, dtype: int64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train['TARGET'].value_counts()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:01.775426Z","iopub.status.busy":"2021-12-29T07:43:01.774662Z","iopub.status.idle":"2021-12-29T07:43:01.973585Z","shell.execute_reply":"2021-12-29T07:43:01.972795Z","shell.execute_reply.started":"2021-12-29T07:43:01.775393Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<AxesSubplot:ylabel='Frequency'>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["train['TARGET'].astype(int).plot.hist()"]},{"cell_type":"markdown","metadata":{},"source":["From this information, we see this is an **imbalanced class** problem. There are far more loans that were repaid on time than loans that were not repaid. Once we get into more sophisticated machine learning models, we can **weight the classes** by their representation in the data to reflect this imbalance."]},{"cell_type":"markdown","metadata":{},"source":["## Examine Missing Values\n","Next we can look at the number and percentage of missing values in each column."]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:01.975441Z","iopub.status.busy":"2021-12-29T07:43:01.974736Z","iopub.status.idle":"2021-12-29T07:43:01.981695Z","shell.execute_reply":"2021-12-29T07:43:01.980183Z","shell.execute_reply.started":"2021-12-29T07:43:01.975407Z"},"trusted":true},"outputs":[],"source":["def missing_values_table(df) :\n","    mis_val = df.isnull().sum()\n","    mis_val_percent = mis_val/len(df)*100\n","    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n","    \n","    mis_val_table_rename_columns = mis_val_table.rename(columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n","    \n","    mis_val_table_rename_columns = mis_val_table_rename_columns[mis_val_table_rename_columns.iloc[:,1]!=0].sort_values('% of Total Values', ascending=False).round(1)\n","    print('total columns : ' + str(df.shape[1]) + '\\n' + 'missing values : ' + str(mis_val_table_rename_columns.shape[0]))\n","    return mis_val_table_rename_columns"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:01.983769Z","iopub.status.busy":"2021-12-29T07:43:01.983369Z","iopub.status.idle":"2021-12-29T07:43:02.237698Z","shell.execute_reply":"2021-12-29T07:43:02.236950Z","shell.execute_reply.started":"2021-12-29T07:43:01.983729Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["total columns : 122\n","missing values : 67\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Missing Values</th>\n","      <th>% of Total Values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>COMMONAREA_MEDI</th>\n","      <td>214865</td>\n","      <td>69.9</td>\n","    </tr>\n","    <tr>\n","      <th>COMMONAREA_AVG</th>\n","      <td>214865</td>\n","      <td>69.9</td>\n","    </tr>\n","    <tr>\n","      <th>COMMONAREA_MODE</th>\n","      <td>214865</td>\n","      <td>69.9</td>\n","    </tr>\n","    <tr>\n","      <th>NONLIVINGAPARTMENTS_MEDI</th>\n","      <td>213514</td>\n","      <td>69.4</td>\n","    </tr>\n","    <tr>\n","      <th>NONLIVINGAPARTMENTS_MODE</th>\n","      <td>213514</td>\n","      <td>69.4</td>\n","    </tr>\n","    <tr>\n","      <th>NONLIVINGAPARTMENTS_AVG</th>\n","      <td>213514</td>\n","      <td>69.4</td>\n","    </tr>\n","    <tr>\n","      <th>FONDKAPREMONT_MODE</th>\n","      <td>210295</td>\n","      <td>68.4</td>\n","    </tr>\n","    <tr>\n","      <th>LIVINGAPARTMENTS_MODE</th>\n","      <td>210199</td>\n","      <td>68.4</td>\n","    </tr>\n","    <tr>\n","      <th>LIVINGAPARTMENTS_MEDI</th>\n","      <td>210199</td>\n","      <td>68.4</td>\n","    </tr>\n","    <tr>\n","      <th>LIVINGAPARTMENTS_AVG</th>\n","      <td>210199</td>\n","      <td>68.4</td>\n","    </tr>\n","    <tr>\n","      <th>FLOORSMIN_MODE</th>\n","      <td>208642</td>\n","      <td>67.8</td>\n","    </tr>\n","    <tr>\n","      <th>FLOORSMIN_MEDI</th>\n","      <td>208642</td>\n","      <td>67.8</td>\n","    </tr>\n","    <tr>\n","      <th>FLOORSMIN_AVG</th>\n","      <td>208642</td>\n","      <td>67.8</td>\n","    </tr>\n","    <tr>\n","      <th>YEARS_BUILD_MODE</th>\n","      <td>204488</td>\n","      <td>66.5</td>\n","    </tr>\n","    <tr>\n","      <th>YEARS_BUILD_MEDI</th>\n","      <td>204488</td>\n","      <td>66.5</td>\n","    </tr>\n","    <tr>\n","      <th>YEARS_BUILD_AVG</th>\n","      <td>204488</td>\n","      <td>66.5</td>\n","    </tr>\n","    <tr>\n","      <th>OWN_CAR_AGE</th>\n","      <td>202929</td>\n","      <td>66.0</td>\n","    </tr>\n","    <tr>\n","      <th>LANDAREA_AVG</th>\n","      <td>182590</td>\n","      <td>59.4</td>\n","    </tr>\n","    <tr>\n","      <th>LANDAREA_MEDI</th>\n","      <td>182590</td>\n","      <td>59.4</td>\n","    </tr>\n","    <tr>\n","      <th>LANDAREA_MODE</th>\n","      <td>182590</td>\n","      <td>59.4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          Missing Values  % of Total Values\n","COMMONAREA_MEDI                   214865               69.9\n","COMMONAREA_AVG                    214865               69.9\n","COMMONAREA_MODE                   214865               69.9\n","NONLIVINGAPARTMENTS_MEDI          213514               69.4\n","NONLIVINGAPARTMENTS_MODE          213514               69.4\n","NONLIVINGAPARTMENTS_AVG           213514               69.4\n","FONDKAPREMONT_MODE                210295               68.4\n","LIVINGAPARTMENTS_MODE             210199               68.4\n","LIVINGAPARTMENTS_MEDI             210199               68.4\n","LIVINGAPARTMENTS_AVG              210199               68.4\n","FLOORSMIN_MODE                    208642               67.8\n","FLOORSMIN_MEDI                    208642               67.8\n","FLOORSMIN_AVG                     208642               67.8\n","YEARS_BUILD_MODE                  204488               66.5\n","YEARS_BUILD_MEDI                  204488               66.5\n","YEARS_BUILD_AVG                   204488               66.5\n","OWN_CAR_AGE                       202929               66.0\n","LANDAREA_AVG                      182590               59.4\n","LANDAREA_MEDI                     182590               59.4\n","LANDAREA_MODE                     182590               59.4"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["missing_values = missing_values_table(train)\n","missing_values.head(20)"]},{"cell_type":"markdown","metadata":{},"source":["When it comes time to build our machine learning models, we will have to fill in these missing values (known as imputation). In later work, we will use models such as XGBoost that can handle missing values with no need for imputation. Another option would be to drop columns with a high percentage of missing values, although it is impossible to know ahead of time if these columns will be helpful to our model. Therefore, we will keep all of the columns for now.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Column Types\n","Let's look at the number of columns of each data type. int64 and float64 are numeric variables (which can be either discrete or continuous). object columns contain strings and are categorical features. ."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:02.239053Z","iopub.status.busy":"2021-12-29T07:43:02.238803Z","iopub.status.idle":"2021-12-29T07:43:02.250701Z","shell.execute_reply":"2021-12-29T07:43:02.249791Z","shell.execute_reply.started":"2021-12-29T07:43:02.239019Z"},"trusted":true},"outputs":[{"data":{"text/plain":["float64    65\n","int64      41\n","object     16\n","dtype: int64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["train.dtypes.value_counts()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:02.253520Z","iopub.status.busy":"2021-12-29T07:43:02.251941Z","iopub.status.idle":"2021-12-29T07:43:02.584256Z","shell.execute_reply":"2021-12-29T07:43:02.583215Z","shell.execute_reply.started":"2021-12-29T07:43:02.253420Z"},"trusted":true},"outputs":[{"data":{"text/plain":["NAME_CONTRACT_TYPE             2\n","CODE_GENDER                    3\n","FLAG_OWN_CAR                   2\n","FLAG_OWN_REALTY                2\n","NAME_TYPE_SUITE                7\n","NAME_INCOME_TYPE               8\n","NAME_EDUCATION_TYPE            5\n","NAME_FAMILY_STATUS             6\n","NAME_HOUSING_TYPE              6\n","OCCUPATION_TYPE               18\n","WEEKDAY_APPR_PROCESS_START     7\n","ORGANIZATION_TYPE             58\n","FONDKAPREMONT_MODE             4\n","HOUSETYPE_MODE                 3\n","WALLSMATERIAL_MODE             7\n","EMERGENCYSTATE_MODE            2\n","dtype: int64"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["train.select_dtypes('object').apply(pd.Series.nunique, axis=0)"]},{"cell_type":"markdown","metadata":{},"source":["Most of the categorical variables have a relatively small number of unique entries. We will need to find a way to deal with these categorical variables!\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Encoding Categorical Variables\n","Before we go any further, we need to deal with pesky categorical variables. A machine learning model unfortunately cannot deal with categorical variables (except for some models such as LightGBM). Therefore, we have to find a way to encode (represent) these variables as numbers before handing them off to the model. There are two main ways to carry out this process:"]},{"cell_type":"markdown","metadata":{},"source":["* Label encoding: assign each unique category in a categorical variable with an integer. No new columns are created.\n","* One-hot encoding: create a new column for each unique category in a categorical variable. Each observation recieves a 1 in the column for its corresponding category and a 0 in all other new columns"]},{"cell_type":"markdown","metadata":{},"source":["레이블 인코딩의 문제는 범주에 임의의 순서를 부여한다는 것입니다. 각 범주에 할당된 값은 무작위이며 범주의 고유한 측면을 반영하지 않습니다. 위의 예에서 프로그래머는 4를, 데이터 과학자는 1을 받지만 동일한 프로세스를 다시 수행하면 레이블이 바뀌거나 완전히 다를 수 있습니다. 정수의 실제 할당은 임의적입니다. 따라서 레이블 인코딩을 수행할 때 모델은 기능의 상대 값(예: 프로그래머 = 4 및 데이터 과학자 = 1)을 사용하여 우리가 원하지 않는 가중치를 할당할 수 있습니다. 범주형 변수(예: 남성/여성)에 대해 고유한 값이 두 개뿐인 경우 레이블 인코딩은 괜찮지만 고유 범주가 2개 이상인 경우 원 핫 인코딩이 안전한 옵션입니다."]},{"cell_type":"markdown","metadata":{},"source":["이러한 접근 방식의 상대적 장점에 대해 약간의 논쟁이 있으며 일부 모델은 문제 없이 레이블로 인코딩된 범주형 변수를 처리할 수 있습니다. 다음은 좋은 스택 오버플로 토론입니다. 클래스가 많은 범주형 변수의 경우 원-핫 인코딩이 범주에 임의의 값을 부과하지 않기 때문에 가장 안전한 접근 방식이라고 생각합니다. 원-핫 인코딩의 유일한 단점은 기능의 수(데이터 차원)가 많은 범주의 범주형 변수로 폭발할 수 있다는 것입니다. 이를 처리하기 위해 원-핫 인코딩을 수행한 후 PCA 또는 기타 차원 축소 방법을 수행하여 차원 수를 줄일 수 있습니다(여전히 정보를 보존하려고 시도하는 동안).\n"]},{"cell_type":"markdown","metadata":{},"source":["In this notebook, we will use Label Encoding for any categorical variables with only 2 categories and One-Hot Encoding for any categorical variables with more than 2 categories. This process may need to change as we get further into the project, but for now, we will see where this gets us. (We will also not use any dimensionality reduction in this notebook but will explore in future iterations)."]},{"cell_type":"markdown","metadata":{},"source":["## Label Encoding and One-Hot Encoding\n","Let's implement the policy described above: for any categorical variable (dtype == object) with 2 unique categories, we will use label encoding, and for any categorical variable with more than 2 unique categories, we will use one-hot encoding.\n","\n","For label encoding, we use the Scikit-Learn LabelEncoder and for one-hot encoding, the pandas get_dummies(df) function."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:02.586161Z","iopub.status.busy":"2021-12-29T07:43:02.585856Z","iopub.status.idle":"2021-12-29T07:43:03.625339Z","shell.execute_reply":"2021-12-29T07:43:03.624197Z","shell.execute_reply.started":"2021-12-29T07:43:02.586121Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["3 columns were label encoded\n"]}],"source":["le = LabelEncoder()\n","le_count=0\n","\n","for col in train :\n","    if train[col].dtype == 'object' :\n","        if len(list(train[col].unique())) <= 2 :\n","            le.fit(train[col])\n","            train[col] = le.transform(train[col])\n","            test[col] = le.transform(test[col])\n","            \n","            le_count+=1\n","\n","print('{} columns were label encoded'.format(le_count))"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:03.629162Z","iopub.status.busy":"2021-12-29T07:43:03.628870Z","iopub.status.idle":"2021-12-29T07:43:04.594200Z","shell.execute_reply":"2021-12-29T07:43:04.592964Z","shell.execute_reply.started":"2021-12-29T07:43:03.629133Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train feature (307511, 243)\n","test feature (48744, 239)\n"]}],"source":["train = pd.get_dummies(train)\n","test = pd.get_dummies(test)\n","print('train feature', train.shape)\n","print('test feature', test.shape)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-12-27T02:38:23.89371Z","iopub.status.busy":"2021-12-27T02:38:23.893405Z","iopub.status.idle":"2021-12-27T02:38:23.915607Z","shell.execute_reply":"2021-12-27T02:38:23.915025Z","shell.execute_reply.started":"2021-12-27T02:38:23.893663Z"}},"source":["### Aligning Training and Testing Data\n","There need to be the same features (columns) in both the training and testing data. One-hot encoding has created more columns in the training data because there were some categorical variables with categories not represented in the testing data. To remove the columns in the training data that are not in the testing data, we need to align the dataframes. First we extract the target column from the training data (because this is not in the testing data but we need to keep this information). When we do the align, we must make sure to set axis = 1 to align the dataframes based on the columns and not on the rows!"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:04.598096Z","iopub.status.busy":"2021-12-29T07:43:04.597858Z","iopub.status.idle":"2021-12-29T07:43:04.783229Z","shell.execute_reply":"2021-12-29T07:43:04.782216Z","shell.execute_reply.started":"2021-12-29T07:43:04.598068Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train feature (307511, 240)\n","test feature (48744, 239)\n"]}],"source":["train_labels = train['TARGET']\n","\n","train, test = train.align(test, join = 'inner', axis = 1)\n","\n","train['TARGET'] = train_labels\n","\n","print('train feature', train.shape)\n","print('test feature', test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Back to Exploratory Data Analysis¶\n","### Anomalies\n","One problem we always want to be on the lookout for when doing EDA is anomalies within the data. These may be due to mis-typed numbers, errors in measuring equipment, or they could be valid but extreme measurements. One way to support anomalies quantitatively is by looking at the **statistics of a column using the describe method**. The numbers in the DAYS_BIRTH column are negative because they are recorded relative to the current loan application. To see these stats in years, we can mutliple by -1 and divide by the number of days in a year:"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:04.784748Z","iopub.status.busy":"2021-12-29T07:43:04.784477Z","iopub.status.idle":"2021-12-29T07:43:04.792958Z","shell.execute_reply":"2021-12-29T07:43:04.792037Z","shell.execute_reply.started":"2021-12-29T07:43:04.784705Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0    -9461\n","1   -16765\n","2   -19046\n","3   -19005\n","4   -19932\n","Name: DAYS_BIRTH, dtype: int64"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["train['DAYS_BIRTH'].head()"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:04.794800Z","iopub.status.busy":"2021-12-29T07:43:04.794421Z","iopub.status.idle":"2021-12-29T07:43:04.821404Z","shell.execute_reply":"2021-12-29T07:43:04.820873Z","shell.execute_reply.started":"2021-12-29T07:43:04.794761Z"},"trusted":true},"outputs":[{"data":{"text/plain":["count    307511.000000\n","mean         43.936973\n","std          11.956133\n","min          20.517808\n","25%          34.008219\n","50%          43.150685\n","75%          53.923288\n","max          69.120548\n","Name: DAYS_BIRTH, dtype: float64"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["(train['DAYS_BIRTH']/-365).describe()"]},{"cell_type":"markdown","metadata":{},"source":["Those ages look reasonable. There are no outliers for the age on either the high or low end. How about the days of employment?\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:04.822700Z","iopub.status.busy":"2021-12-29T07:43:04.822521Z","iopub.status.idle":"2021-12-29T07:43:04.840148Z","shell.execute_reply":"2021-12-29T07:43:04.838946Z","shell.execute_reply.started":"2021-12-29T07:43:04.822674Z"},"trusted":true},"outputs":[{"data":{"text/plain":["count    307511.000000\n","mean      63815.045904\n","std      141275.766519\n","min      -17912.000000\n","25%       -2760.000000\n","50%       -1213.000000\n","75%        -289.000000\n","max      365243.000000\n","Name: DAYS_EMPLOYED, dtype: float64"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["train['DAYS_EMPLOYED'].describe()"]},{"cell_type":"markdown","metadata":{},"source":["That doesn't look right! The maximum value (besides being positive) is about 1000 years!\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:04.841915Z","iopub.status.busy":"2021-12-29T07:43:04.841657Z","iopub.status.idle":"2021-12-29T07:43:04.856412Z","shell.execute_reply":"2021-12-29T07:43:04.855544Z","shell.execute_reply.started":"2021-12-29T07:43:04.841875Z"},"trusted":true},"outputs":[{"data":{"text/plain":[" 365243    55374\n","-200         156\n","-224         152\n","-230         151\n","-199         151\n","           ...  \n","-13961         1\n","-11827         1\n","-10176         1\n","-9459          1\n","-8694          1\n","Name: DAYS_EMPLOYED, Length: 12574, dtype: int64"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["train['DAYS_EMPLOYED'].value_counts()"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:04.858380Z","iopub.status.busy":"2021-12-29T07:43:04.858008Z","iopub.status.idle":"2021-12-29T07:43:05.093814Z","shell.execute_reply":"2021-12-29T07:43:05.093170Z","shell.execute_reply.started":"2021-12-29T07:43:04.858349Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Text(0.5, 0, 'days employment')"]},"execution_count":24,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["train['DAYS_EMPLOYED'].plot.hist(title='Days employment histrogram')\n","plt.xlabel('days employment')"]},{"cell_type":"markdown","metadata":{},"source":["Just out of curiousity, let's subset the anomalous clients and see if they tend to have higher or low rates of default than the rest of the clients.\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:05.095892Z","iopub.status.busy":"2021-12-29T07:43:05.095207Z","iopub.status.idle":"2021-12-29T07:43:05.312019Z","shell.execute_reply":"2021-12-29T07:43:05.311146Z","shell.execute_reply.started":"2021-12-29T07:43:05.095852Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["non-anomalies defalut :  8.65997453765215\n","anomalies default :  5.399646043269405\n","There are 55374 anomalies on DAYS_EMPLOYED\n"]}],"source":["anom = train[train['DAYS_EMPLOYED']==365243]\n","non_anom = train[train['DAYS_EMPLOYED'] !=365243]\n","print('non-anomalies defalut : ',non_anom['TARGET'].mean()*100)\n","print('anomalies default : ', anom['TARGET'].mean()*100)\n","print('There are {} anomalies on DAYS_EMPLOYED'.format(len(anom)))"]},{"cell_type":"markdown","metadata":{},"source":["Well that is extremely interesting! It turns out that the anomalies have a lower rate of default.\n","\n","Handling the anomalies depends on the exact situation, with no set rules. One of the safest approaches is just to set the anomalies to a missing value and then have them filled in (using Imputation) before machine learning. In this case, since all the anomalies have the exact same value, we want to fill them in with the same value in case all of these loans share something in common. The anomalous values seem to have some importance, so we want to tell the machine learning model if we did in fact fill in these values. As a solution, we will fill in the anomalous values with not a number (np.nan) and then create a new boolean column indicating whether or not the value was anomalous."]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:05.313302Z","iopub.status.busy":"2021-12-29T07:43:05.313094Z","iopub.status.idle":"2021-12-29T07:43:05.559634Z","shell.execute_reply":"2021-12-29T07:43:05.558636Z","shell.execute_reply.started":"2021-12-29T07:43:05.313261Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Text(0.5, 0, 'days employment')"]},"execution_count":26,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["train['DAYS_EMPLOYED_ANOM'] = train['DAYS_EMPLOYED']==365243\n","train['DAYS_EMPLOYED'].replace({365243 : np.nan}, inplace=True)\n","train['DAYS_EMPLOYED'].plot.hist(title='Days Employment histogram')\n","plt.xlabel('days employment')\n"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-12-27T03:18:01.730766Z","iopub.status.busy":"2021-12-27T03:18:01.729993Z","iopub.status.idle":"2021-12-27T03:18:01.737513Z","shell.execute_reply":"2021-12-27T03:18:01.736747Z","shell.execute_reply.started":"2021-12-27T03:18:01.730723Z"}},"source":["분포는 우리가 예상하는 것과 훨씬 더 일치하는 것으로 보이며, 이러한 값이 원래 비정상임을 모델에 알려주는 새 열도 만들었습니다. 열). 데이터 프레임에 DAYS가 있는 다른 열은 명백한 이상값 없이 예상한 것과 같습니다.\n","\n","매우 중요한 메모로, 훈련 데이터에 대해 수행하는 모든 작업은 테스트 데이터에도 수행해야 합니다. 테스트 데이터에서 새 열을 만들고 기존 열을 np.nan으로 채우도록 합시다."]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:05.561884Z","iopub.status.busy":"2021-12-29T07:43:05.561363Z","iopub.status.idle":"2021-12-29T07:43:05.574457Z","shell.execute_reply":"2021-12-29T07:43:05.573404Z","shell.execute_reply.started":"2021-12-29T07:43:05.561844Z"},"trusted":true},"outputs":[],"source":["test['DAYS_EMPLOYED_ANOM'] = train['DAYS_EMPLOYED_ANOM'] == 365243\n","test['DAYS_EMPLOYED'] = test['DAYS_EMPLOYED'].replace({365243:np.nan},inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Correlations\n","Now that we have dealt with the categorical variables and the outliers, let's continue with the EDA. One way to try and understand the data is by looking for correlations between the features and the target. We can calculate the Pearson correlation coefficient between every variable and the target using the *.corr* dataframe method.\n","\n","The correlation coefficient is not the greatest method to represent \"relevance\" of a feature, but it does give us an idea of possible relationships within the data. Some general interpretations of the absolute value of the correlation coefficent are:\n","\n","* .00-.19 “very weak”\n","* .20-.39 “weak”\n","* .40-.59 “moderate”\n","* .60-.79 “strong”\n","* .80-1.0 “very strong”"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:05.576005Z","iopub.status.busy":"2021-12-29T07:43:05.575782Z","iopub.status.idle":"2021-12-29T07:43:42.743260Z","shell.execute_reply":"2021-12-29T07:43:42.741903Z","shell.execute_reply.started":"2021-12-29T07:43:05.575976Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Most Positive Correlations : \n"," OCCUPATION_TYPE_Laborers                             0.043019\n","FLAG_DOCUMENT_3                                      0.044346\n","REG_CITY_NOT_LIVE_CITY                               0.044395\n","FLAG_EMP_PHONE                                       0.045982\n","NAME_EDUCATION_TYPE_Secondary / secondary special    0.049824\n","REG_CITY_NOT_WORK_CITY                               0.050994\n","DAYS_ID_PUBLISH                                      0.051457\n","CODE_GENDER_M                                        0.054713\n","DAYS_LAST_PHONE_CHANGE                               0.055218\n","NAME_INCOME_TYPE_Working                             0.057481\n","REGION_RATING_CLIENT                                 0.058899\n","REGION_RATING_CLIENT_W_CITY                          0.060893\n","DAYS_EMPLOYED                                        0.074958\n","DAYS_BIRTH                                           0.078239\n","TARGET                                               1.000000\n","Name: TARGET, dtype: float64\n","\n"," Most Negative Correlations : \n"," EXT_SOURCE_3                           -0.178919\n","EXT_SOURCE_2                           -0.160472\n","EXT_SOURCE_1                           -0.155317\n","NAME_EDUCATION_TYPE_Higher education   -0.056593\n","CODE_GENDER_F                          -0.054704\n","NAME_INCOME_TYPE_Pensioner             -0.046209\n","DAYS_EMPLOYED_ANOM                     -0.045987\n","ORGANIZATION_TYPE_XNA                  -0.045987\n","FLOORSMAX_AVG                          -0.044003\n","FLOORSMAX_MEDI                         -0.043768\n","FLOORSMAX_MODE                         -0.043226\n","EMERGENCYSTATE_MODE_No                 -0.042201\n","HOUSETYPE_MODE_block of flats          -0.040594\n","AMT_GOODS_PRICE                        -0.039645\n","REGION_POPULATION_RELATIVE             -0.037227\n","Name: TARGET, dtype: float64\n"]}],"source":["correlations = train.corr()['TARGET'].sort_values()\n","\n","print('Most Positive Correlations : \\n', correlations.tail(15))\n","print('\\n Most Negative Correlations : \\n', correlations.head(15))"]},{"cell_type":"markdown","metadata":{},"source":["Let's take a look at some of more significant correlations: the DAYS_BIRTH is the most positive correlation. (except for TARGET because the correlation of a variable with itself is always 1!) Looking at the documentation, DAYS_BIRTH is the age in days of the client at the time of the loan in negative days (for whatever reason!). The correlation is positive, but the value of this feature is actually negative, meaning that as the client gets older, they are less likely to default on their loan (ie the target == 0). That's a little confusing, so we will take the absolute value of the feature and then the correlation will be negative.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Effect of Age on Repayment¶\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:42.745429Z","iopub.status.busy":"2021-12-29T07:43:42.745107Z","iopub.status.idle":"2021-12-29T07:43:42.760563Z","shell.execute_reply":"2021-12-29T07:43:42.759031Z","shell.execute_reply.started":"2021-12-29T07:43:42.745391Z"},"trusted":true},"outputs":[{"data":{"text/plain":["-0.07823930830984513"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["train['DAYS_BIRTH'] = abs(train['DAYS_BIRTH'])\n","train['DAYS_BIRTH'].corr(train['TARGET'])"]},{"cell_type":"markdown","metadata":{},"source":["As the client gets older, there is a negative linear relationship with the target meaning that as clients get older, they tend to repay their loans on time more often.\n","\n","Let's start looking at this variable. First, we can make a histogram of the age. We will put the x axis in years to make the plot a little more understandable."]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:42.763664Z","iopub.status.busy":"2021-12-29T07:43:42.763219Z","iopub.status.idle":"2021-12-29T07:43:43.025866Z","shell.execute_reply":"2021-12-29T07:43:43.024695Z","shell.execute_reply.started":"2021-12-29T07:43:42.763632Z"},"trusted":true},"outputs":[],"source":["# plt.style.use('fivethirtyeight')\n","# plt.hist(train['DAYS_BIRTH'] / 365, edgecolor='k', bins=25)\n","# plt.title('Age of client')\n","# plt.xlabel('Age')\n","# plt.ylabel('Count')"]},{"cell_type":"markdown","metadata":{},"source":["그 자체로 연령 분포는 모든 연령이 합리적이므로 이상치가 없다는 것 외에는 많은 것을 말해주지 않습니다. 대상에 대한 연령의 영향을 시각화하기 위해 다음으로 대상 값으로 색칠된 커널 밀도 추정 플롯(kernel density estimation plot, KDE)을 만듭니다. 커널 밀도 추정 플롯은 단일 변수의 분포를 보여주며 평활 히스토그램으로 생각할 수 있습니다(각 데이터 포인트에서 커널, 일반적으로 가우스를 계산한 다음 모든 개별 커널을 평균화하여 하나의 평활한 히스토그램을 생성합니다. 곡선). 이 그래프에는 seaborn kdeplot을 사용합니다.\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:43.027700Z","iopub.status.busy":"2021-12-29T07:43:43.027437Z","iopub.status.idle":"2021-12-29T07:43:44.151827Z","shell.execute_reply":"2021-12-29T07:43:44.150981Z","shell.execute_reply.started":"2021-12-29T07:43:43.027668Z"},"trusted":true},"outputs":[],"source":["# plt.figure(figsize=(10,8))\n","\n","# sns.kdeplot(train.loc[train['TARGET']==0, 'DAYS_BIRTH'] / 365, label = 'target==0')\n","# sns.kdeplot(train.loc[train['TARGET']==1, 'DAYS_BIRTH'] / 365, label = 'target==1')\n","# plt.xlabel('age')\n","# plt.ylabel('density')\n","# plt.title('distribution of ages')\n","# plt.legend()"]},{"cell_type":"markdown","metadata":{},"source":["target == 1 곡선은 범위의 더 어린 쪽 끝으로 기울어집니다. 이것이 유의미한 상관관계는 아니지만(-0.07 상관 계수), 이 변수는 대상에 영향을 미치기 때문에 기계 학습 모델에서 유용할 것 같습니다. 이 관계를 다른 방식으로 살펴보겠습니다. 연령대별 평균 대출 상환 실패.\n","\n","이 그래프를 만들기 위해 먼저 연령 범주를 각각 5년 단위로 자릅니다. 그런 다음 각 빈에 대해 대상의 평균 값을 계산하여 각 연령 범주에서 상환되지 않은 대출 비율을 알려줍니다."]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:44.153428Z","iopub.status.busy":"2021-12-29T07:43:44.153198Z","iopub.status.idle":"2021-12-29T07:43:44.233563Z","shell.execute_reply":"2021-12-29T07:43:44.232530Z","shell.execute_reply.started":"2021-12-29T07:43:44.153400Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TARGET</th>\n","      <th>DAYS_BIRTH</th>\n","      <th>YEARS_BIRTH</th>\n","      <th>YEARS_BINNED</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>9461</td>\n","      <td>25.920548</td>\n","      <td>(25.0, 30.0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>16765</td>\n","      <td>45.931507</td>\n","      <td>(45.0, 50.0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>19046</td>\n","      <td>52.180822</td>\n","      <td>(50.0, 55.0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>19005</td>\n","      <td>52.068493</td>\n","      <td>(50.0, 55.0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>19932</td>\n","      <td>54.608219</td>\n","      <td>(50.0, 55.0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   TARGET  DAYS_BIRTH  YEARS_BIRTH  YEARS_BINNED\n","0       1        9461    25.920548  (25.0, 30.0]\n","1       0       16765    45.931507  (45.0, 50.0]\n","2       0       19046    52.180822  (50.0, 55.0]\n","3       0       19005    52.068493  (50.0, 55.0]\n","4       0       19932    54.608219  (50.0, 55.0]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["age_data = train[['TARGET','DAYS_BIRTH']]\n","age_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH']/365\n","\n","age_data['YEARS_BINNED'] = pd.cut(age_data['YEARS_BIRTH'], bins = np.linspace(20,70, num=11))\n","age_data.head()"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:44.235036Z","iopub.status.busy":"2021-12-29T07:43:44.234830Z","iopub.status.idle":"2021-12-29T07:43:44.260448Z","shell.execute_reply":"2021-12-29T07:43:44.259721Z","shell.execute_reply.started":"2021-12-29T07:43:44.235007Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TARGET</th>\n","      <th>DAYS_BIRTH</th>\n","      <th>YEARS_BIRTH</th>\n","    </tr>\n","    <tr>\n","      <th>YEARS_BINNED</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>(20.0, 25.0]</th>\n","      <td>0.123036</td>\n","      <td>8532.795625</td>\n","      <td>23.377522</td>\n","    </tr>\n","    <tr>\n","      <th>(25.0, 30.0]</th>\n","      <td>0.111436</td>\n","      <td>10155.219250</td>\n","      <td>27.822518</td>\n","    </tr>\n","    <tr>\n","      <th>(30.0, 35.0]</th>\n","      <td>0.102814</td>\n","      <td>11854.848377</td>\n","      <td>32.479037</td>\n","    </tr>\n","    <tr>\n","      <th>(35.0, 40.0]</th>\n","      <td>0.089414</td>\n","      <td>13707.908253</td>\n","      <td>37.555913</td>\n","    </tr>\n","    <tr>\n","      <th>(40.0, 45.0]</th>\n","      <td>0.078491</td>\n","      <td>15497.661233</td>\n","      <td>42.459346</td>\n","    </tr>\n","    <tr>\n","      <th>(45.0, 50.0]</th>\n","      <td>0.074171</td>\n","      <td>17323.900441</td>\n","      <td>47.462741</td>\n","    </tr>\n","    <tr>\n","      <th>(50.0, 55.0]</th>\n","      <td>0.066968</td>\n","      <td>19196.494791</td>\n","      <td>52.593136</td>\n","    </tr>\n","    <tr>\n","      <th>(55.0, 60.0]</th>\n","      <td>0.055314</td>\n","      <td>20984.262742</td>\n","      <td>57.491131</td>\n","    </tr>\n","    <tr>\n","      <th>(60.0, 65.0]</th>\n","      <td>0.052737</td>\n","      <td>22780.547460</td>\n","      <td>62.412459</td>\n","    </tr>\n","    <tr>\n","      <th>(65.0, 70.0]</th>\n","      <td>0.037270</td>\n","      <td>24292.614340</td>\n","      <td>66.555108</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                TARGET    DAYS_BIRTH  YEARS_BIRTH\n","YEARS_BINNED                                     \n","(20.0, 25.0]  0.123036   8532.795625    23.377522\n","(25.0, 30.0]  0.111436  10155.219250    27.822518\n","(30.0, 35.0]  0.102814  11854.848377    32.479037\n","(35.0, 40.0]  0.089414  13707.908253    37.555913\n","(40.0, 45.0]  0.078491  15497.661233    42.459346\n","(45.0, 50.0]  0.074171  17323.900441    47.462741\n","(50.0, 55.0]  0.066968  19196.494791    52.593136\n","(55.0, 60.0]  0.055314  20984.262742    57.491131\n","(60.0, 65.0]  0.052737  22780.547460    62.412459\n","(65.0, 70.0]  0.037270  24292.614340    66.555108"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["age_groups = age_data.groupby('YEARS_BINNED').mean()\n","age_groups"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:44.262180Z","iopub.status.busy":"2021-12-29T07:43:44.261912Z","iopub.status.idle":"2021-12-29T07:43:44.499325Z","shell.execute_reply":"2021-12-29T07:43:44.498405Z","shell.execute_reply.started":"2021-12-29T07:43:44.262150Z"},"trusted":true},"outputs":[],"source":["# plt.figure(figsize=(8,8))\n","# plt.bar(age_groups.index.astype(str), 100* age_groups['TARGET'])\n","# plt.xticks(rotation = 75); plt.xlabel('Age Group (years)'); plt.ylabel('Failure to Repay (%)')\n","# plt.title('Failure to Repay by Age Group')"]},{"cell_type":"markdown","metadata":{},"source":["분명한 추세가 있습니다. 젊은 신청자는 대출을 상환하지 않을 가능성이 더 큽니다! 연체율은 최연소 3세 10% 이상, 고령 5% 미만이다.\n","\n","이것은 은행에서 직접 사용할 수 있는 정보입니다. 젊은 고객은 대출금을 상환할 가능성이 적기 때문에 더 많은 지침이나 재무 계획 팁을 제공받아야 합니다. 그렇다고 해서 은행이 어린 고객들을 차별해야 한다는 의미는 아니지만, 젊은 고객들이 제때 지불할 수 있도록 예방 조치를 취하는 것이 현명할 것입니다."]},{"cell_type":"markdown","metadata":{},"source":["### Exterior Sources\n","The 3 variables with the strongest negative correlations with the target are EXT_SOURCE_1, EXT_SOURCE_2, and EXT_SOURCE_3. According to the documentation, these features represent a \"normalized score from external data source\". I'm not sure what this exactly means, but it may be a cumulative sort of credit rating made using numerous sources of data.\n","\n","Let's take a look at these variables.\n","\n","First, we can show the correlations of the EXT_SOURCE features with the target and with each other."]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:44.501507Z","iopub.status.busy":"2021-12-29T07:43:44.501190Z","iopub.status.idle":"2021-12-29T07:43:44.545376Z","shell.execute_reply":"2021-12-29T07:43:44.544371Z","shell.execute_reply.started":"2021-12-29T07:43:44.501474Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TARGET</th>\n","      <th>EXT_SOURCE_1</th>\n","      <th>EXT_SOURCE_2</th>\n","      <th>EXT_SOURCE_3</th>\n","      <th>DAYS_BIRTH</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>TARGET</th>\n","      <td>1.000000</td>\n","      <td>-0.155317</td>\n","      <td>-0.160472</td>\n","      <td>-0.178919</td>\n","      <td>-0.078239</td>\n","    </tr>\n","    <tr>\n","      <th>EXT_SOURCE_1</th>\n","      <td>-0.155317</td>\n","      <td>1.000000</td>\n","      <td>0.213982</td>\n","      <td>0.186846</td>\n","      <td>0.600610</td>\n","    </tr>\n","    <tr>\n","      <th>EXT_SOURCE_2</th>\n","      <td>-0.160472</td>\n","      <td>0.213982</td>\n","      <td>1.000000</td>\n","      <td>0.109167</td>\n","      <td>0.091996</td>\n","    </tr>\n","    <tr>\n","      <th>EXT_SOURCE_3</th>\n","      <td>-0.178919</td>\n","      <td>0.186846</td>\n","      <td>0.109167</td>\n","      <td>1.000000</td>\n","      <td>0.205478</td>\n","    </tr>\n","    <tr>\n","      <th>DAYS_BIRTH</th>\n","      <td>-0.078239</td>\n","      <td>0.600610</td>\n","      <td>0.091996</td>\n","      <td>0.205478</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                TARGET  EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  DAYS_BIRTH\n","TARGET        1.000000     -0.155317     -0.160472     -0.178919   -0.078239\n","EXT_SOURCE_1 -0.155317      1.000000      0.213982      0.186846    0.600610\n","EXT_SOURCE_2 -0.160472      0.213982      1.000000      0.109167    0.091996\n","EXT_SOURCE_3 -0.178919      0.186846      0.109167      1.000000    0.205478\n","DAYS_BIRTH   -0.078239      0.600610      0.091996      0.205478    1.000000"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["ext_data = train[['TARGET','EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3','DAYS_BIRTH']]\n","ext_data_corrs = ext_data.corr()\n","ext_data_corrs"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:44.546736Z","iopub.status.busy":"2021-12-29T07:43:44.546451Z","iopub.status.idle":"2021-12-29T07:43:44.837018Z","shell.execute_reply":"2021-12-29T07:43:44.836246Z","shell.execute_reply.started":"2021-12-29T07:43:44.546704Z"},"trusted":true},"outputs":[],"source":["# plt.figure(figsize=(8,6))\n","# sns.heatmap(ext_data_corrs, cmap=plt.cm.RdYlBu_r, annot=True, vmin=-0.25, vmax=0.6)\n","# plt.title('Correlation heatmap')"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-12-27T06:23:05.552486Z","iopub.status.busy":"2021-12-27T06:23:05.55167Z","iopub.status.idle":"2021-12-27T06:23:05.918421Z","shell.execute_reply":"2021-12-27T06:23:05.917341Z","shell.execute_reply.started":"2021-12-27T06:23:05.552442Z"}},"source":["All three EXT_SOURCE features have negative correlations with the target, indicating that as the value of the EXT_SOURCE increases, the client is more likely to repay the loan. We can also see that DAYS_BIRTH is positively correlated with EXT_SOURCE_1 indicating that maybe one of the factors in this score is the client age.\n","\n","Next we can look at the distribution of each of these features colored by the value of the target. This will let us visualize the effect of this variable on the target."]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:44.838361Z","iopub.status.busy":"2021-12-29T07:43:44.838130Z","iopub.status.idle":"2021-12-29T07:43:48.197274Z","shell.execute_reply":"2021-12-29T07:43:48.196066Z","shell.execute_reply.started":"2021-12-29T07:43:44.838330Z"},"trusted":true},"outputs":[],"source":["# plt.figure(figsize=(10,12))\n","\n","# for i, source in enumerate(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']) :\n","#     plt.subplot(3,1,i+1)\n","#     sns.kdeplot(train.loc[train['TARGET']==0, source], label='target==0')\n","#     sns.kdeplot(train.loc[train['TARGET']==1, source], label='target==1')\n","#     plt.title('distribution of {} by Target'.format(source))\n","#     plt.xlabel('{}'.format(source))\n","#     plt.legend()\n","# plt.tight_layout(h_pad=2.5)"]},{"cell_type":"markdown","metadata":{},"source":["EXT_SOURCE_3 displays the greatest difference between the values of the target. We can clearly see that this feature has some relationship to the likelihood of an applicant to repay a loan. The relationship is not very strong (in fact they are all considered very weak, but these variables will still be useful for a machine learning model to predict whether or not an applicant will repay a loan on time."]},{"cell_type":"markdown","metadata":{},"source":["### Pairs Plot\n","As a final exploratory plot, we can make a pairs plot of the EXT_SOURCE variables and the DAYS_BIRTH variable. The Pairs Plot is a great exploration tool because it lets us see relationships between multiple pairs of variables as well as distributions of single variables. Here we are using the seaborn visualization library and the PairGrid function to create a Pairs Plot with scatterplots on the upper triangle, histograms on the diagonal, and 2D kernel density plots and correlation coefficients on the lower triangle.\n","\n","If you don't understand this code, that's all right! Plotting in Python can be overly complex, and for anything beyond the simplest graphs, I usually find an existing implementation and adapt the code (don't repeat yourself)!"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:43:48.198968Z","iopub.status.busy":"2021-12-29T07:43:48.198746Z","iopub.status.idle":"2021-12-29T07:47:18.447999Z","shell.execute_reply":"2021-12-29T07:47:18.447353Z","shell.execute_reply.started":"2021-12-29T07:43:48.198939Z"},"trusted":true},"outputs":[],"source":["# plot_data = ext_data.drop(columns = ['DAYS_BIRTH']).copy()\n","# plot_data['YEARS_BIRTH'] = age_data['YEARS_BIRTH']\n","# plot_data = plot_data.dropna().loc[:100000,:]\n","\n","# grid = sns.PairGrid(data = plot_data, size = 3, diag_sharey=False, hue='TARGET', vars = [x for x in list(plot_data.columns) if x != 'TARGET'])\n","\n","# grid.map_upper(plt.scatter, alpha=0.2)\n","# grid.map_diag(sns.kdeplot)\n","# grid.map_lower(sns.kdeplot, cmap = plt.cm.OrRd_r)\n","# plt.suptitle('Ext Source and Age Features Pairs Plot', size = 32, y = 1.05)\n"]},{"cell_type":"markdown","metadata":{},"source":["이 그림에서 빨간색은 상환되지 않은 대출을 나타내고 파란색은 상환된 대출을 나타냅니다. 데이터 내에서 다양한 관계를 볼 수 있습니다. EXT_SOURCE_1과 DAYS_BIRTH(또는 이에 상응하는 YEARS_BIRTH) 사이에 적당한 양의 선형 관계가 있는 것으로 보이며, 이는 이 기능이 클라이언트의 연령을 고려할 수 있음을 나타냅니다.\n"]},{"cell_type":"markdown","metadata":{},"source":["# Feature Engineering\n","Kaggle competitions are won by feature engineering: those win are those who can create the most useful features out of the data. (This is true for the most part as the winning models, at least for structured data, all tend to be variants on gradient boosting). This represents one of the patterns in machine learning: feature engineering has a greater return on investment than model building and hyperparameter tuning. This is a great article on the subject). As Andrew Ng is fond of saying: \"applied machine learning is basically feature engineering.\"\n","\n","While choosing the right model and optimal settings are important, the model can only learn from the data it is given. Making sure this data is as relevant to the task as possible is the job of the data scientist (and maybe some automated tools to help us out).\n","\n","Feature engineering refers to a geneal process and can involve both feature construction: adding new features from the existing data, and feature selection: choosing only the most important features or other methods of dimensionality reduction. There are many techniques we can use to both create features and select features.\n","\n","We will do a lot of feature engineering when we start using the other data sources, but in this notebook we will try only two simple feature construction methods:\n","\n","* Polynomial features\n","* Domain knowledge features"]},{"cell_type":"markdown","metadata":{},"source":["## Polynomial Features\n","One simple feature construction method is called polynomial features. In this method, we make features that are powers of existing features as well as interaction terms between existing features. For example, we can create variables EXT_SOURCE_1^2 and EXT_SOURCE_2^2 and also variables such as EXT_SOURCE_1 x EXT_SOURCE_2, EXT_SOURCE_1 x EXT_SOURCE_2^2, EXT_SOURCE_1^2 x EXT_SOURCE_2^2, and so on. These features that are a combination of multiple individual variables are called interaction terms because they capture the interactions between variables. In other words, while two variables by themselves may not have a strong influence on the target, combining them together into a single interaction variable might show a relationship with the target. Interaction terms are commonly used in statistical models to capture the effects of multiple variables, but I do not see them used as often in machine learning. Nonetheless, we can try out a few to see if they might help our model to predict whether or not a client will repay a loan.\n","\n","Jake VanderPlas writes about polynomial features in his excellent book Python for Data Science for those who want more information.\n","\n","In the following code, we create polynomial features using the EXT_SOURCE variables and the DAYS_BIRTH variable. Scikit-Learn has a useful class called PolynomialFeatures that creates the polynomials and the interaction terms up to a specified degree. We can use a degree of 3 to see the results (when we are creating polynomial features, we want to avoid using too high of a degree, both because the number of features scales exponentially with the degree, and because we can run into problems with overfitting)."]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:47:18.449988Z","iopub.status.busy":"2021-12-29T07:47:18.449161Z","iopub.status.idle":"2021-12-29T07:47:18.661813Z","shell.execute_reply":"2021-12-29T07:47:18.661344Z","shell.execute_reply.started":"2021-12-29T07:47:18.449948Z"},"trusted":true},"outputs":[],"source":["poly_features = train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']]\n","poly_features_test = test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n","\n","# imputer for handling missing values\n","from sklearn.impute import SimpleImputer\n","imputer = SimpleImputer(strategy = 'median')\n","\n","poly_target = poly_features['TARGET']\n","\n","poly_features = poly_features.drop(columns=['TARGET'])\n","\n","# impute missing values\n","poly_features = imputer.fit_transform(poly_features)\n","poly_features_test = imputer.fit_transform(poly_features_test)\n","\n","from sklearn.preprocessing import PolynomialFeatures\n","\n","# create polynomial object\n","poly_transformer = PolynomialFeatures(degree=3)"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:47:18.663080Z","iopub.status.busy":"2021-12-29T07:47:18.662630Z","iopub.status.idle":"2021-12-29T07:47:18.772661Z","shell.execute_reply":"2021-12-29T07:47:18.771872Z","shell.execute_reply.started":"2021-12-29T07:47:18.663054Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(307511, 35)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["poly_transformer.fit(poly_features)\n","\n","poly_features = poly_transformer.transform(poly_features)\n","poly_features_test = poly_transformer.transform(poly_features_test)\n","poly_features.shape"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-12-28T04:17:52.75483Z","iopub.status.busy":"2021-12-28T04:17:52.754244Z","iopub.status.idle":"2021-12-28T04:17:52.760176Z","shell.execute_reply":"2021-12-28T04:17:52.759351Z","shell.execute_reply.started":"2021-12-28T04:17:52.754791Z"}},"source":["This creates a considerable number of new features. To get the names we have to use the polynomial features get_feature_names method."]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:47:18.773804Z","iopub.status.busy":"2021-12-29T07:47:18.773615Z","iopub.status.idle":"2021-12-29T07:47:18.780084Z","shell.execute_reply":"2021-12-29T07:47:18.779419Z","shell.execute_reply.started":"2021-12-29T07:47:18.773771Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['1',\n"," 'EXT_SOURCE_1',\n"," 'EXT_SOURCE_2',\n"," 'EXT_SOURCE_3',\n"," 'DAYS_BIRTH',\n"," 'EXT_SOURCE_1^2',\n"," 'EXT_SOURCE_1 EXT_SOURCE_2',\n"," 'EXT_SOURCE_1 EXT_SOURCE_3',\n"," 'EXT_SOURCE_1 DAYS_BIRTH',\n"," 'EXT_SOURCE_2^2',\n"," 'EXT_SOURCE_2 EXT_SOURCE_3',\n"," 'EXT_SOURCE_2 DAYS_BIRTH',\n"," 'EXT_SOURCE_3^2',\n"," 'EXT_SOURCE_3 DAYS_BIRTH',\n"," 'DAYS_BIRTH^2',\n"," 'EXT_SOURCE_1^3',\n"," 'EXT_SOURCE_1^2 EXT_SOURCE_2',\n"," 'EXT_SOURCE_1^2 EXT_SOURCE_3',\n"," 'EXT_SOURCE_1^2 DAYS_BIRTH',\n"," 'EXT_SOURCE_1 EXT_SOURCE_2^2',\n"," 'EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3',\n"," 'EXT_SOURCE_1 EXT_SOURCE_2 DAYS_BIRTH',\n"," 'EXT_SOURCE_1 EXT_SOURCE_3^2',\n"," 'EXT_SOURCE_1 EXT_SOURCE_3 DAYS_BIRTH',\n"," 'EXT_SOURCE_1 DAYS_BIRTH^2',\n"," 'EXT_SOURCE_2^3',\n"," 'EXT_SOURCE_2^2 EXT_SOURCE_3',\n"," 'EXT_SOURCE_2^2 DAYS_BIRTH',\n"," 'EXT_SOURCE_2 EXT_SOURCE_3^2',\n"," 'EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH',\n"," 'EXT_SOURCE_2 DAYS_BIRTH^2',\n"," 'EXT_SOURCE_3^3',\n"," 'EXT_SOURCE_3^2 DAYS_BIRTH',\n"," 'EXT_SOURCE_3 DAYS_BIRTH^2',\n"," 'DAYS_BIRTH^3']"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["poly_transformer.get_feature_names(input_features = ['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3','DAYS_BIRTH'])"]},{"cell_type":"markdown","metadata":{},"source":["There are 35 features with individual features raised to powers up to degree 3 and interaction terms. Now, we can see whether any of these new features are correlated with the target."]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:47:18.781397Z","iopub.status.busy":"2021-12-29T07:47:18.780983Z","iopub.status.idle":"2021-12-29T07:47:19.650423Z","shell.execute_reply":"2021-12-29T07:47:19.649365Z","shell.execute_reply.started":"2021-12-29T07:47:18.781369Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["EXT_SOURCE_2 EXT_SOURCE_3                -0.193939\n","EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3   -0.189605\n","EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH     -0.181283\n","EXT_SOURCE_2^2 EXT_SOURCE_3              -0.176428\n","EXT_SOURCE_2 EXT_SOURCE_3^2              -0.172282\n","EXT_SOURCE_1 EXT_SOURCE_2                -0.166625\n","EXT_SOURCE_1 EXT_SOURCE_3                -0.164065\n","EXT_SOURCE_2                             -0.160295\n","EXT_SOURCE_2 DAYS_BIRTH                  -0.156873\n","EXT_SOURCE_1 EXT_SOURCE_2^2              -0.156867\n","Name: TARGET, dtype: float64\n","DAYS_BIRTH     -0.078239\n","DAYS_BIRTH^2   -0.076672\n","DAYS_BIRTH^3   -0.074273\n","TARGET          1.000000\n","1                    NaN\n","Name: TARGET, dtype: float64\n"]}],"source":["# create dataframe of the features\n","poly_features = pd.DataFrame(poly_features, columns=poly_transformer.get_feature_names(['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3','DAYS_BIRTH']))\n","\n","# add in the target\n","poly_features['TARGET'] = poly_target\n","\n","poly_corrs = poly_features.corr()['TARGET'].sort_values()\n","\n","print(poly_corrs.head(10))\n","print(poly_corrs.tail(5))"]},{"cell_type":"markdown","metadata":{},"source":["Several of the new variables have a greater (in terms of absolute magnitude) correlation with the target than the original features. When we build machine learning models, we can try with and without these features to determine if they actually help the model learn.\n","\n","We will add these features to a copy of the training and testing data and then evaluate models with and without the features. Many times in machine learning, the only way to know if an approach will work is to try it out!"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:47:19.651867Z","iopub.status.busy":"2021-12-29T07:47:19.651659Z","iopub.status.idle":"2021-12-29T07:47:21.207179Z","shell.execute_reply":"2021-12-29T07:47:21.206581Z","shell.execute_reply.started":"2021-12-29T07:47:19.651840Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(307511, 275) \t (48744, 275)\n"]}],"source":["# put test features into dataframe\n","poly_features_test = pd.DataFrame(poly_features_test, columns=poly_transformer.get_feature_names(['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3','DAYS_BIRTH']))\n","\n","# merge polynomial features into training dataframe\n","poly_features['SK_ID_CURR'] = train['SK_ID_CURR']\n","train_poly = train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')\n","\n","# merge polynomial features into testing dataframe\n","poly_features_test['SK_ID_CURR'] = test['SK_ID_CURR']\n","test_poly = test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')\n","\n","# align the dataframe\n","train_poly, test_poly = train_poly.align(test_poly, join = 'inner', axis=1)\n","\n","print(train_poly.shape, '\\t', test_poly.shape)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-12-28T04:32:47.781755Z","iopub.status.busy":"2021-12-28T04:32:47.781434Z","iopub.status.idle":"2021-12-28T04:32:47.790215Z","shell.execute_reply":"2021-12-28T04:32:47.789162Z","shell.execute_reply.started":"2021-12-28T04:32:47.78172Z"}},"source":["## Domain Knowledge Features\n","Maybe it's not entirely correct to call this \"domain knowledge\" because I'm not a credit expert, but perhaps we could call this \"attempts at applying limited financial knowledge\". In this frame of mind, we can make a couple features that attempt to capture what we think may be important for telling whether a client will default on a loan. Here I'm going to use five features that were inspired by this script by Aguiar:\n","\n","* CREDIT_INCOME_PERCENT: the percentage of the credit amount relative to a client's income\n","* ANNUITY_INCOME_PERCENT: the percentage of the loan annuity relative to a client's income\n","* CREDIT_TERM: the length of the payment in months (since the annuity is the monthly amount due\n","* DAYS_EMPLOYED_PERCENT: the percentage of the days employed relative to the client's age\n","\n","Again, thanks to Aguiar and his great script for exploring these features."]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:47:21.209276Z","iopub.status.busy":"2021-12-29T07:47:21.209014Z","iopub.status.idle":"2021-12-29T07:47:21.268263Z","shell.execute_reply":"2021-12-29T07:47:21.266794Z","shell.execute_reply.started":"2021-12-29T07:47:21.209246Z"},"trusted":true},"outputs":[],"source":["train_domain = train.copy()\n","test_domain = test.copy()"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:47:21.270211Z","iopub.status.busy":"2021-12-29T07:47:21.269976Z","iopub.status.idle":"2021-12-29T07:47:21.282684Z","shell.execute_reply":"2021-12-29T07:47:21.281443Z","shell.execute_reply.started":"2021-12-29T07:47:21.270188Z"},"trusted":true},"outputs":[],"source":["train_domain['CREDIT_INCOME_PERCENT'] = train_domain['AMT_CREDIT'] / train_domain['AMT_INCOME_TOTAL']\n","train_domain['ANNUITY_INCOME_PERCENT'] = train_domain['AMT_ANNUITY'] / train_domain['AMT_INCOME_TOTAL']\n","train_domain['CREDIT_TERM'] = train_domain['AMT_ANNUITY'] / train_domain['AMT_CREDIT']\n","train_domain['DAYS_EMPLOYED_PERCENT'] = train_domain['DAYS_EMPLOYED'] / train_domain['DAYS_BIRTH']"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:47:21.288167Z","iopub.status.busy":"2021-12-29T07:47:21.287802Z","iopub.status.idle":"2021-12-29T07:47:21.305208Z","shell.execute_reply":"2021-12-29T07:47:21.303753Z","shell.execute_reply.started":"2021-12-29T07:47:21.288129Z"},"trusted":true},"outputs":[],"source":["test_domain['CREDIT_INCOME_PERCENT'] = test_domain['AMT_CREDIT'] / test_domain['AMT_INCOME_TOTAL']\n","test_domain['ANNUITY_INCOME_PERCENT'] = test_domain['AMT_ANNUITY'] / test_domain['AMT_INCOME_TOTAL']\n","test_domain['CREDIT_TERM'] = test_domain['AMT_ANNUITY'] / test_domain['AMT_CREDIT']\n","test_domain['DAYS_EMPLOYED_PERCENT'] = test_domain['DAYS_EMPLOYED'] / test_domain['DAYS_BIRTH']"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:47:21.306773Z","iopub.status.busy":"2021-12-29T07:47:21.306559Z","iopub.status.idle":"2021-12-29T07:47:21.362864Z","shell.execute_reply":"2021-12-29T07:47:21.362450Z","shell.execute_reply.started":"2021-12-29T07:47:21.306744Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SK_ID_CURR</th>\n","      <th>NAME_CONTRACT_TYPE</th>\n","      <th>FLAG_OWN_CAR</th>\n","      <th>FLAG_OWN_REALTY</th>\n","      <th>CNT_CHILDREN</th>\n","      <th>AMT_INCOME_TOTAL</th>\n","      <th>AMT_CREDIT</th>\n","      <th>AMT_ANNUITY</th>\n","      <th>AMT_GOODS_PRICE</th>\n","      <th>REGION_POPULATION_RELATIVE</th>\n","      <th>...</th>\n","      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n","      <th>WALLSMATERIAL_MODE_Wooden</th>\n","      <th>EMERGENCYSTATE_MODE_No</th>\n","      <th>EMERGENCYSTATE_MODE_Yes</th>\n","      <th>TARGET</th>\n","      <th>DAYS_EMPLOYED_ANOM</th>\n","      <th>CREDIT_INCOME_PERCENT</th>\n","      <th>ANNUITY_INCOME_PERCENT</th>\n","      <th>CREDIT_TERM</th>\n","      <th>DAYS_EMPLOYED_PERCENT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>100002</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>202500.0</td>\n","      <td>406597.5</td>\n","      <td>24700.5</td>\n","      <td>351000.0</td>\n","      <td>0.018801</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>2.007889</td>\n","      <td>0.121978</td>\n","      <td>0.060749</td>\n","      <td>-0.067329</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>100003</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>270000.0</td>\n","      <td>1293502.5</td>\n","      <td>35698.5</td>\n","      <td>1129500.0</td>\n","      <td>0.003541</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>4.790750</td>\n","      <td>0.132217</td>\n","      <td>0.027598</td>\n","      <td>-0.070862</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>100004</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>67500.0</td>\n","      <td>135000.0</td>\n","      <td>6750.0</td>\n","      <td>135000.0</td>\n","      <td>0.010032</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>2.000000</td>\n","      <td>0.100000</td>\n","      <td>0.050000</td>\n","      <td>-0.011814</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>100006</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>135000.0</td>\n","      <td>312682.5</td>\n","      <td>29686.5</td>\n","      <td>297000.0</td>\n","      <td>0.008019</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>2.316167</td>\n","      <td>0.219900</td>\n","      <td>0.094941</td>\n","      <td>-0.159905</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>100007</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>121500.0</td>\n","      <td>513000.0</td>\n","      <td>21865.5</td>\n","      <td>513000.0</td>\n","      <td>0.028663</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>4.222222</td>\n","      <td>0.179963</td>\n","      <td>0.042623</td>\n","      <td>-0.152418</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>307506</th>\n","      <td>456251</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>157500.0</td>\n","      <td>254700.0</td>\n","      <td>27558.0</td>\n","      <td>225000.0</td>\n","      <td>0.032561</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>1.617143</td>\n","      <td>0.174971</td>\n","      <td>0.108198</td>\n","      <td>-0.025303</td>\n","    </tr>\n","    <tr>\n","      <th>307507</th>\n","      <td>456252</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>72000.0</td>\n","      <td>269550.0</td>\n","      <td>12001.5</td>\n","      <td>225000.0</td>\n","      <td>0.025164</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","      <td>3.743750</td>\n","      <td>0.166687</td>\n","      <td>0.044524</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>307508</th>\n","      <td>456253</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>153000.0</td>\n","      <td>677664.0</td>\n","      <td>29979.0</td>\n","      <td>585000.0</td>\n","      <td>0.005002</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>4.429176</td>\n","      <td>0.195941</td>\n","      <td>0.044239</td>\n","      <td>-0.529266</td>\n","    </tr>\n","    <tr>\n","      <th>307509</th>\n","      <td>456254</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>171000.0</td>\n","      <td>370107.0</td>\n","      <td>20205.0</td>\n","      <td>319500.0</td>\n","      <td>0.005313</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>2.164368</td>\n","      <td>0.118158</td>\n","      <td>0.054592</td>\n","      <td>-0.400134</td>\n","    </tr>\n","    <tr>\n","      <th>307510</th>\n","      <td>456255</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>157500.0</td>\n","      <td>675000.0</td>\n","      <td>49117.5</td>\n","      <td>675000.0</td>\n","      <td>0.046220</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>4.285714</td>\n","      <td>0.311857</td>\n","      <td>0.072767</td>\n","      <td>-0.074869</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>307511 rows × 245 columns</p>\n","</div>"],"text/plain":["        SK_ID_CURR  NAME_CONTRACT_TYPE  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n","0           100002                   0             0                1   \n","1           100003                   0             0                0   \n","2           100004                   1             1                1   \n","3           100006                   0             0                1   \n","4           100007                   0             0                1   \n","...            ...                 ...           ...              ...   \n","307506      456251                   0             0                0   \n","307507      456252                   0             0                1   \n","307508      456253                   0             0                1   \n","307509      456254                   0             0                1   \n","307510      456255                   0             0                0   \n","\n","        CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n","0                  0          202500.0    406597.5      24700.5   \n","1                  0          270000.0   1293502.5      35698.5   \n","2                  0           67500.0    135000.0       6750.0   \n","3                  0          135000.0    312682.5      29686.5   \n","4                  0          121500.0    513000.0      21865.5   \n","...              ...               ...         ...          ...   \n","307506             0          157500.0    254700.0      27558.0   \n","307507             0           72000.0    269550.0      12001.5   \n","307508             0          153000.0    677664.0      29979.0   \n","307509             0          171000.0    370107.0      20205.0   \n","307510             0          157500.0    675000.0      49117.5   \n","\n","        AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  ...  \\\n","0              351000.0                    0.018801  ...   \n","1             1129500.0                    0.003541  ...   \n","2              135000.0                    0.010032  ...   \n","3              297000.0                    0.008019  ...   \n","4              513000.0                    0.028663  ...   \n","...                 ...                         ...  ...   \n","307506         225000.0                    0.032561  ...   \n","307507         225000.0                    0.025164  ...   \n","307508         585000.0                    0.005002  ...   \n","307509         319500.0                    0.005313  ...   \n","307510         675000.0                    0.046220  ...   \n","\n","        WALLSMATERIAL_MODE_Stone, brick  WALLSMATERIAL_MODE_Wooden  \\\n","0                                     1                          0   \n","1                                     0                          0   \n","2                                     0                          0   \n","3                                     0                          0   \n","4                                     0                          0   \n","...                                 ...                        ...   \n","307506                                1                          0   \n","307507                                1                          0   \n","307508                                0                          0   \n","307509                                1                          0   \n","307510                                0                          0   \n","\n","        EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  TARGET  \\\n","0                            1                        0       1   \n","1                            1                        0       0   \n","2                            0                        0       0   \n","3                            0                        0       0   \n","4                            0                        0       0   \n","...                        ...                      ...     ...   \n","307506                       1                        0       0   \n","307507                       1                        0       0   \n","307508                       1                        0       0   \n","307509                       1                        0       1   \n","307510                       1                        0       0   \n","\n","        DAYS_EMPLOYED_ANOM  CREDIT_INCOME_PERCENT  ANNUITY_INCOME_PERCENT  \\\n","0                    False               2.007889                0.121978   \n","1                    False               4.790750                0.132217   \n","2                    False               2.000000                0.100000   \n","3                    False               2.316167                0.219900   \n","4                    False               4.222222                0.179963   \n","...                    ...                    ...                     ...   \n","307506               False               1.617143                0.174971   \n","307507                True               3.743750                0.166687   \n","307508               False               4.429176                0.195941   \n","307509               False               2.164368                0.118158   \n","307510               False               4.285714                0.311857   \n","\n","        CREDIT_TERM  DAYS_EMPLOYED_PERCENT  \n","0          0.060749              -0.067329  \n","1          0.027598              -0.070862  \n","2          0.050000              -0.011814  \n","3          0.094941              -0.159905  \n","4          0.042623              -0.152418  \n","...             ...                    ...  \n","307506     0.108198              -0.025303  \n","307507     0.044524                    NaN  \n","307508     0.044239              -0.529266  \n","307509     0.054592              -0.400134  \n","307510     0.072767              -0.074869  \n","\n","[307511 rows x 245 columns]"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["train_domain"]},{"cell_type":"markdown","metadata":{},"source":["### Visualize New Variables\n","We should explore these domain knowledge variables visually in a graph. For all of these, we will make the same KDE plot colored by the value of the TARGET."]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T05:46:04.549701Z","iopub.status.busy":"2021-12-29T05:46:04.549484Z","iopub.status.idle":"2021-12-29T05:46:10.826652Z","shell.execute_reply":"2021-12-29T05:46:10.825236Z","shell.execute_reply.started":"2021-12-29T05:46:04.549670Z"},"trusted":true},"outputs":[],"source":["# plt.figure(figsize=(12,20))\n","\n","# for i, feature in enumerate(['CREDIT_INCOME_PERCENT', 'ANNUITY_INCOME_PERCENT', 'CREDIT_TERM', 'DAYS_EMPLOYED_PERCENT']):\n","#     plt.subplot(4,1,i+1)\n","#     sns.kdeplot(train_domain.loc[train_domain['TARGET']==0,feature], label = 'target==0')\n","#     sns.kdeplot(train_domain.loc[train_domain['TARGET']==1,feature], label = 'target==1')\n","    \n","#     plt.title('ditribution of {} by target value'.format(feature))\n","#     plt.xlabel('{}'.format(feature))\n","#     plt.ylabel('density')\n","\n","\n","#     plt.tight_layout(h_pad=2.5)"]},{"cell_type":"markdown","metadata":{},"source":["It's hard to say ahead of time if these new features will be useful. The only way to tell for sure is to try them out!\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Baseline\n","For a naive baseline, we could guess the same value for all examples on the testing set. We are asked to predict the probability of not repaying the loan, so if we are entirely unsure, we would guess 0.5 for all observations on the test set. This will get us a Reciever Operating Characteristic Area Under the Curve (AUC ROC) of 0.5 in the competition (random guessing on a classification task will score a 0.5).\n","\n","Since we already know what score we are going to get, we don't really need to make a naive baseline guess. Let's use a slightly more sophisticated model for our actual baseline: Logistic Regression.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Logistic Regression Implementation\n","Here I will focus on implementing the model rather than explaining the details, but for those who want to learn more about the theory of machine learning algorithms, I recommend both An Introduction to Statistical Learning and Hands-On Machine Learning with Scikit-Learn and TensorFlow. Both of these books present the theory and also the code needed to make the models (in R and Python respectively). They both teach with the mindset that the best way to learn is by doing, and they are very effective!\n","\n","To get a baseline, we will use all of the features after encoding the categorical variables. We will preprocess the data by filling in the missing values (imputation) and normalizing the range of the features (feature scaling). The following code performs both of these preprocessing steps."]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T05:46:10.828348Z","iopub.status.busy":"2021-12-29T05:46:10.828068Z","iopub.status.idle":"2021-12-29T05:46:39.934155Z","shell.execute_reply":"2021-12-29T05:46:39.932979Z","shell.execute_reply.started":"2021-12-29T05:46:10.828317Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(307511, 240) \t (48744, 240)\n"]}],"source":["from sklearn.preprocessing import MinMaxScaler\n","from sklearn.impute import SimpleImputer\n","\n","# drop 'target' from training data\n","if 'TARGET' in train :\n","    train_input = train.drop(columns=['TARGET'])\n","else :\n","    train_input = train.copy()\n","    \n","# feature names\n","features = list(train_input.columns)\n","\n","test_input = test.copy()\n","\n","# imputation of missing values\n","imputer = SimpleImputer(strategy = 'median')\n","\n","# scaler to 0-1\n","scaler = MinMaxScaler(feature_range=(0,1))\n","\n","# fit on the training data\n","imputer.fit(train_input)\n","\n","# transform both train, test data on missing values\n","train_input = imputer.transform(train_input)\n","test_input = imputer.transform(test_input)\n","\n","# transform both train, test data on scaler\n","scaler.fit(train_input)\n","train_input = scaler.transform(train_input)\n","test_input = scaler.transform(test_input)\n","\n","print(train_input.shape, '\\t', test_input.shape)"]},{"cell_type":"markdown","metadata":{},"source":["We will use LogisticRegressionfrom Scikit-Learn for our first model. The only change we will make from the default model settings is to lower the regularization parameter, C, which controls the amount of overfitting (a lower value should decrease overfitting). This will get us slightly better results than the default LogisticRegression, but it still will set a low bar for any future models.\n","\n","Here we use the familiar Scikit-Learn modeling syntax: we first create the model, then we train the model using .fit and then we make predictions on the testing data using .predict_proba (remember that we want probabilities and not a 0 or 1)."]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T05:46:39.935631Z","iopub.status.busy":"2021-12-29T05:46:39.935427Z","iopub.status.idle":"2021-12-29T05:46:39.939653Z","shell.execute_reply":"2021-12-29T05:46:39.939100Z","shell.execute_reply.started":"2021-12-29T05:46:39.935604Z"},"trusted":true},"outputs":[],"source":["# from sklearn.linear_model import LogisticRegression\n","\n","# # make the model with the specified regularization parameter\n","# log_reg = LogisticRegression(C=0.0001)\n","\n","# # Train on the training data\n","# log_reg.fit(train_input,train_labels)"]},{"cell_type":"markdown","metadata":{},"source":["Now that the model has been trained, we can use it to make predictions. We want to predict the probabilities of not paying a loan, so we use the model predict.proba method. This returns an m x 2 array where m is the number of observations. The first column is the probability of the target being 0 and the second column is the probability of the target being 1 (so for a single row, the two columns must sum to 1). We want the probability the loan is not repaid, so we will select the second column.\n","\n","The following code makes the predictions and selects the correct column."]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T05:46:39.941336Z","iopub.status.busy":"2021-12-29T05:46:39.940563Z","iopub.status.idle":"2021-12-29T05:46:39.955074Z","shell.execute_reply":"2021-12-29T05:46:39.953622Z","shell.execute_reply.started":"2021-12-29T05:46:39.941263Z"},"trusted":true},"outputs":[],"source":["# # make the predictions\n","# # select the 2nd column for submission\n","# log_reg_pred = log_reg.predict_proba(test_input)[:,1]"]},{"cell_type":"markdown","metadata":{},"source":["The predictions must be in the format shown in the sample_submission.csv file, where there are only two columns: SK_ID_CURR and TARGET. We will create a dataframe in this format from the test set and the predictions called submit."]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T05:46:39.956831Z","iopub.status.busy":"2021-12-29T05:46:39.956502Z","iopub.status.idle":"2021-12-29T05:46:39.975552Z","shell.execute_reply":"2021-12-29T05:46:39.973721Z","shell.execute_reply.started":"2021-12-29T05:46:39.956801Z"},"trusted":true},"outputs":[],"source":["# # submission dataframe\n","# submit = test[['SK_ID_CURR']]\n","# submit['TARGET'] = log_reg_pred\n","# submit.head()"]},{"cell_type":"markdown","metadata":{},"source":["The predictions represent a probability between 0 and 1 that the loan will not be repaid. If we were using these predictions to classify applicants, we could set a probability threshold for determining that a loan is risky."]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T05:46:39.977234Z","iopub.status.busy":"2021-12-29T05:46:39.976642Z","iopub.status.idle":"2021-12-29T05:46:39.989277Z","shell.execute_reply":"2021-12-29T05:46:39.988625Z","shell.execute_reply.started":"2021-12-29T05:46:39.977202Z"},"trusted":true},"outputs":[],"source":["# # save the submission to csv file \n","# submit.to_csv('submission.csv', index = False)"]},{"cell_type":"markdown","metadata":{},"source":["The submission has now been saved to the virtual environment in which our notebook is running. To access the submission, at the end of the notebook, we will hit the blue Commit & Run button at the upper right of the kernel. This runs the entire notebook and then lets us download any files that are created during the run.\n","\n","Once we run the notebook, the files created are available in the Versions tab under the Output sub-tab. From here, the submission files can be submitted to the competition or downloaded. Since there are several models in this notebook, there will be multiple output files.\n","\n","**The logistic regression baseline should score around 0.671 when submitted.**"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-12-28T05:37:05.631158Z","iopub.status.busy":"2021-12-28T05:37:05.630765Z","iopub.status.idle":"2021-12-28T05:37:05.639495Z","shell.execute_reply":"2021-12-28T05:37:05.637987Z","shell.execute_reply.started":"2021-12-28T05:37:05.631117Z"}},"source":["## Improved Model: Random Forest\n","To try and beat the poor performance of our baseline, we can update the algorithm. Let's try using a Random Forest on the same training data to see how that affects performance. The Random Forest is a much more powerful model especially when we use hundreds of trees. We will use 100 trees in the random forest."]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T05:46:39.990698Z","iopub.status.busy":"2021-12-29T05:46:39.990403Z","iopub.status.idle":"2021-12-29T05:46:40.066514Z","shell.execute_reply":"2021-12-29T05:46:40.065328Z","shell.execute_reply.started":"2021-12-29T05:46:39.990670Z"},"trusted":true},"outputs":[],"source":["# from sklearn.ensemble import RandomForestClassifier\n","\n","# random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs=-1)"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T05:46:40.068432Z","iopub.status.busy":"2021-12-29T05:46:40.068173Z","iopub.status.idle":"2021-12-29T05:46:40.191480Z","shell.execute_reply":"2021-12-29T05:46:40.190344Z","shell.execute_reply.started":"2021-12-29T05:46:40.068404Z"},"trusted":true},"outputs":[],"source":["# random_forest.fit(train_input, train_labels)\n","\n","# # extract feature importances\n","# feature_importance_values = random_forest.feature_importances_\n","# feature_importances = pd.DataFrame({'feature' : features, 'importance' : feature_importance_values})\n","\n","# # # make prediction on test data\n","# predictions = random_forest.predict_proba(test_input)[:,1]"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.status.busy":"2021-12-29T05:46:40.192569Z","iopub.status.idle":"2021-12-29T05:46:40.192890Z","shell.execute_reply":"2021-12-29T05:46:40.192740Z","shell.execute_reply.started":"2021-12-29T05:46:40.192722Z"},"trusted":true},"outputs":[],"source":["# # make a submission\n","# submit = test[['SK_ID_CURR']]\n","# submit['TARGET'] = predictions\n","\n","# submit.to_csv('random_forest_baseline.csv',index=False)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-12-28T05:45:03.331988Z","iopub.status.busy":"2021-12-28T05:45:03.331683Z","iopub.status.idle":"2021-12-28T05:45:03.346805Z","shell.execute_reply":"2021-12-28T05:45:03.345242Z","shell.execute_reply.started":"2021-12-28T05:45:03.331954Z"}},"source":["These predictions will also be available when we run the entire notebook.\n","\n","**This model should score around 0.678 when submitted.**"]},{"cell_type":"markdown","metadata":{},"source":["### Make Predictions using Engineered Features\n","The only way to see if the Polynomial Features and Domain knowledge improved the model is to train a test a model on these features! We can then compare the submission performance to that for the model without these features to gauge the effect of our feature engineering."]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.status.busy":"2021-12-29T05:46:40.193957Z","iopub.status.idle":"2021-12-29T05:46:40.194255Z","shell.execute_reply":"2021-12-29T05:46:40.194107Z","shell.execute_reply.started":"2021-12-29T05:46:40.194092Z"},"trusted":true},"outputs":[],"source":["# poly_features_names = list(train_poly.columns)\n","\n","# # imputer\n","# imputer = SimpleImputer(strategy = 'median')\n","\n","# poly_features = imputer.fit_transform(train_poly)\n","# poly_features_test = imputer.transform(test_poly)\n","\n","# # scaler\n","# scaler = MinMaxScaler(feature_range=(0,1))\n","\n","# poly_features = scaler.fit_transform(poly_features)\n","# poly_features_test = scaler.transform(poly_features_test)\n","\n","# random_forest_poly = RandomForestClassifier(n_estimators=100, random_state = 50, verbose =1, n_jobs=-1)"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.status.busy":"2021-12-29T05:46:40.195127Z","iopub.status.idle":"2021-12-29T05:46:40.195437Z","shell.execute_reply":"2021-12-29T05:46:40.195278Z","shell.execute_reply.started":"2021-12-29T05:46:40.195263Z"},"trusted":true},"outputs":[],"source":["# # train on training data\n","# random_forest_poly.fit(poly_features, train_labels)\n","\n","# # prediction on test data\n","# predictions = random_forest_poly.predict_proba(poly_features_test)[:,1]"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.status.busy":"2021-12-29T05:46:40.196442Z","iopub.status.idle":"2021-12-29T05:46:40.196755Z","shell.execute_reply":"2021-12-29T05:46:40.196588Z","shell.execute_reply.started":"2021-12-29T05:46:40.196572Z"},"trusted":true},"outputs":[],"source":["# # Make a submission dataframe\n","# submit = test[['SK_ID_CURR']]\n","# submit['TARGET'] = predictions\n","\n","# # Save the submission dataframe\n","# submit.to_csv('random_forest_baseline_engineered.csv', index = False)"]},{"cell_type":"markdown","metadata":{},"source":["This model scored 0.678 when submitted to the competition, exactly the same as that without the engineered features. Given these results, it does not appear that our feature construction helped in this case."]},{"cell_type":"markdown","metadata":{},"source":["### Testing Domain Features\n","Now we can test the domain features we made by hand."]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.status.busy":"2021-12-29T05:46:40.197604Z","iopub.status.idle":"2021-12-29T05:46:40.197889Z","shell.execute_reply":"2021-12-29T05:46:40.197752Z","shell.execute_reply.started":"2021-12-29T05:46:40.197736Z"},"trusted":true},"outputs":[],"source":["# train_domain = train_domain.drop(columns='TARGET')\n","\n","# domain_feature_names = list(train_domain.columns)\n","\n","# # imputer\n","# imputer = SimpleImputer(strategy='median')\n","\n","# domain_features = imputer.fit_transform(train_domain)\n","# domain_features_test = imputer.transform(test_domain)\n","\n","# # scaler\n","# scaler = MinMaxScaler(feature_range=(0,1))\n","\n","# domain_features = scaler.fit_transform(domain_features)\n","# domain_features_test = scaler.transform(domain_features_test)\n","\n","# random_forest_domain = RandomForestClassifier(n_estimators = 100, random_state=50, verbose=1, n_jobs=-1)\n","\n","# # train on train data\n","# random_forest_domain.fit(domain_features, train_labels)\n","\n","# # extract feature importances\n","# feature_importance_values_domain = random_forest_domain.feature_importances_\n","# feature_importances_domain = pd.DataFrame({'feature' : domain_feature_names, 'importance' : feature_importance_values_domain})\n","\n","# # predition on test data\n","# predictions = random_forest_domain.predict_proba(domain_features_test)[:,1]"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.status.busy":"2021-12-29T05:46:40.198670Z","iopub.status.idle":"2021-12-29T05:46:40.198954Z","shell.execute_reply":"2021-12-29T05:46:40.198814Z","shell.execute_reply.started":"2021-12-29T05:46:40.198799Z"},"trusted":true},"outputs":[],"source":["# # make a submission\n","# submit = test[['SK_ID_CURR']]\n","# submit['TARGET'] = predictions\n","\n","# submit.to_csv('submission.csv',index = False)"]},{"cell_type":"markdown","metadata":{},"source":["**This scores 0.679** when submitted which probably shows that the engineered features do not help in this model (however they do help in the Gradient Boosting Model at the end of the notebook).\n","\n","In later notebooks, we will do more feature engineering by using the information from the other data sources. From experience, this will definitely help our model!"]},{"cell_type":"markdown","metadata":{},"source":["### Model Interpretation: Feature Importances\n","As a simple method to see which variables are the most relevant, we can look at the feature importances of the random forest. Given the correlations we saw in the exploratory data analysis, we should expect that the most important features are the EXT_SOURCE and the DAYS_BIRTH. We may use these feature importances as a method of dimensionality reduction in future work."]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:40:14.469240Z","iopub.status.busy":"2021-12-29T07:40:14.468922Z","iopub.status.idle":"2021-12-29T07:40:14.479219Z","shell.execute_reply":"2021-12-29T07:40:14.478356Z","shell.execute_reply.started":"2021-12-29T07:40:14.469201Z"},"trusted":true},"outputs":[],"source":["def plot_feature_importances(df) :\n","    \n","    # sort feature according to importance\n","    df = df.sort_values('importance', ascending=False).reset_index()\n","    \n","    # Normalize the feature importance to add up to 1\n","    df['importance_normalized'] = df['importance']/df['importance'].sum()\n","    \n","    # make a horizontal bar chart \n","    plt.figure(figsize=(10,6))\n","    ax = plt.subplot()\n","    \n","    # Need to reverse the index to plot most important on top\n","    ax.barh(list(reversed(list(df.index[:15]))), df['importance_normalized'].head(15), align = 'center', edgecolor = 'k')\n","    \n","    # Set the yticks and labels\n","    ax.set_yticks(list(reversed(list(df.index[:15]))))\n","    ax.set_yticklabels(df['feature'].head(15))\n","    \n","    plt.xlabel('Normalized importance')\n","    plt.title('feature importances')\n","    plt.show()\n","    \n","    return df"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.status.busy":"2021-12-29T05:46:40.202234Z","iopub.status.idle":"2021-12-29T05:46:40.202910Z","shell.execute_reply":"2021-12-29T05:46:40.202754Z","shell.execute_reply.started":"2021-12-29T05:46:40.202735Z"},"trusted":true},"outputs":[],"source":["# # feature importance for defalut \n","# feature_importances_sorted = plot_feature_importances(feature_importances)"]},{"cell_type":"markdown","metadata":{},"source":["As expected, the most important features are those dealing with EXT_SOURCE and DAYS_BIRTH. We see that there are only a handful of features with a significant importance to the model, which suggests we may be able to drop many of the features without a decrease in performance (and we may even see an increase in performance.) Feature importances are not the most sophisticated method to interpret a model or perform dimensionality reduction, but they let us start to understand what factors our model takes into account when it makes predictions."]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.status.busy":"2021-12-29T05:46:40.203742Z","iopub.status.idle":"2021-12-29T05:46:40.204332Z","shell.execute_reply":"2021-12-29T05:46:40.204168Z","shell.execute_reply.started":"2021-12-29T05:46:40.204151Z"},"trusted":true},"outputs":[],"source":["# feature_importances_domain_sorted = plot_feature_importances(feature_importances_domain)"]},{"cell_type":"markdown","metadata":{},"source":["We see that all four of our hand-engineered features made it into the top 15 most important! This should give us confidence that our domain knowledge was at least partially on track."]},{"cell_type":"markdown","metadata":{},"source":["# Conclusions\n","In this notebook, we saw how to get started with a Kaggle machine learning competition. We first made sure to understand the data, our task, and the metric by which our submissions will be judged. Then, we performed a fairly simple EDA to try and identify relationships, trends, or anomalies that may help our modeling. Along the way, we performed necessary preprocessing steps such as encoding categorical variables, imputing missing values, and scaling features to a range. Then, we constructed new features out of the existing data to see if doing so could help our model.\n","\n","Once the data exploration, data preparation, and feature engineering was complete, we implemented a baseline model upon which we hope to improve. Then we built a second slightly more complicated model to beat our first score. We also carried out an experiment to determine the effect of adding the engineering variables.\n","\n","We followed the general outline of a machine learning project:\n","\n","Understand the problem and the data\n","Data cleaning and formatting (this was mostly done for us)\n","Exploratory Data Analysis\n","Baseline model\n","Improved model\n","Model interpretation (just a little)\n","Machine learning competitions do differ slightly from typical data science problems in that we are concerned only with achieving the best performance on a single metric and do not care about the interpretation. However, by attempting to understand how our models make decisions, we can try to improve them or examine the mistakes in order to correct the errors. In future notebooks we will look at incorporating more sources of data, building more complex models (by following the code of others), and improving our scores.\n","\n","I hope this notebook was able to get you up and running in this machine learning competition and that you are now ready to go out on your own - with help from the community - and start working on some great problems!\n","\n","Running the notebook: now that we are at the end of the notebook, you can hit the blue Commit & Run button to execute all the code at once. After the run is complete (this should take about 10 minutes), you can then access the files that were created by going to the versions tab and then the output sub-tab. The submission files can be directly submitted to the competition from this tab or they can be downloaded to a local machine and saved. The final part is to share the share the notebook: go to the settings tab and change the visibility to Public. This allows the entire world to see your work!\n","\n","## Follow-up Notebooks\n","For those looking to keep working on this problem, I have a series of follow-up notebooks:\n","\n","Manual Feature Engineering Part One\n","Manual Feature Engineering Part Two\n","Introduction to Automated Feature Engineering\n","Advanced Automated Feature Engineering\n","Feature Selection\n","Intro to Model Tuning: Grid and Random Search\n","As always, I welcome feedback and constructive criticism. I write for Towards Data Science at https://medium.com/@williamkoehrsen/ and can be reached on Twitter at https://twitter.com/koehrsen_will\n","\n","Will"]},{"cell_type":"markdown","metadata":{},"source":["# Just for Fun: Light Gradient Boosting Machine\n","Now (if you want, this part is entirely optional) we can step off the deep end and use a real machine learning model: the gradient boosting machine using the LightGBM library! The Gradient Boosting Machine is currently the leading model for learning on structured datasets (especially on Kaggle) and we will probably need some form of this model to do well in the competition. Don't worry, even if this code looks intimidating, it's just a series of small steps that build up to a complete model. I added this code just to show what may be in store for this project, and because it gets us a slightly better score on the leaderboard. In future notebooks we will see how to work with more advanced models (which mostly means adapting existing code to make it work better), feature engineering, and feature selection. See you in the next notebook!"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:26:58.192114Z","iopub.status.busy":"2021-12-29T07:26:58.191847Z","iopub.status.idle":"2021-12-29T07:26:58.220353Z","shell.execute_reply":"2021-12-29T07:26:58.219728Z","shell.execute_reply.started":"2021-12-29T07:26:58.192082Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import KFold\n","from sklearn.metrics import roc_auc_score\n","import lightgbm as lgb\n","import gc\n","\n","def model(features, test_features, encoding = 'ohe', n_folds=5) :\n","    train_ids = features['SK_ID_CURR']\n","    test_ids = test_features['SK_ID_CURR']\n","    \n","    labels = features['TARGET']\n","    \n","    features = features.drop(columns=['SK_ID_CURR','TARGET'])\n","    test_features = test_features.drop(columns=['SK_ID_CURR'])\n","    \n","    # One-Hot encoding\n","    if encoding == 'ohe' :\n","        features = pd.get_dummies(features)\n","        test_features = pd.get_dummies(test_features)\n","        \n","        # align the dataframe\n","        features, test_features = features.align(test_features, join='inner', axis=1)\n","        \n","        cat_indices = 'auto'\n","    \n","    # Label encoding\n","    elif encoding == 'le' :\n","        label_encoder = LabelEncoder()\n","        \n","        # list for storing categorical indices\n","        cat_indices = []\n","        \n","        for i, col in enumerate(features) :\n","            if features[col].dtype == 'object' :\n","                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n","                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n","                \n","                # record the categorical indices\n","                cat_indices.append(i)\n","    \n","    else :\n","        raise ValueError(\"encoding must be either 'ohe' or 'le'\")\n","        \n","    print('training data shape : ', features.shape)\n","    print('test data shape : ', test_features.shape)\n","    \n","    features_name = list(features.columns)\n","    \n","    features = np.array(features)\n","    test_features = np.array(test_features)\n","    \n","    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n","    \n","    feature_importance_values = np.zeros(len(features_name))\n","    \n","    test_predictions = np.zeros(test_features.shape[0])\n","    \n","    out_of_fold = np.zeros(features.shape[0])\n","    \n","    valid_scores = []\n","    train_scores = []\n","    \n","    for train_indices, valid_indices in k_fold.split(features) :\n","        # training, validation data \n","        train_features, train_labels = features[train_indices], labels[train_indices]\n","        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n","        \n","        # create model\n","        model = lgb.LGBMClassifier(n_estimators =10000, objective = 'binary', class_weight = 'balanced', learning_rate = 0.05,\n","                                   reg_alpha = 0.1, reg_lambda = 0.1, subsample = 0.8, n_jobs=-1, random_state = 50)\n","        # train model\n","        model.fit(train_features, train_labels, eval_metric = 'auc', \n","                  eval_set = [(valid_features,valid_labels),(train_features,train_labels)],\n","                  eval_names = ['valid','train'], categorical_feature = cat_indices, early_stopping_rounds = 100, verbose=200)\n","        \n","        # record best iteration\n","        best_iteration = model.best_iteration_\n","        \n","        # record the feature importances\n","        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n","        \n","        # make prediction\n","        test_predictions += model.predict_proba(test_features, num_interation = best_iteration)[:, 1] / k_fold.n_splits\n","        \n","        # record the out of fold predictions\n","        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:,1]\n","        \n","        # record the best score\n","        valid_score = model.best_score_['valid']['auc']\n","        train_score = model.best_score_['train']['auc']\n","        \n","        valid_scores.append(valid_score)\n","        train_scores.append(train_score)\n","        \n","        # clean up memory\n","        gc.enable()\n","        del model, train_features, valid_features\n","        gc.collect()\n","        \n","    # make submission \n","    submission = pd.DataFrame({'SK_ID_CURR' : test_ids, 'TARGET' : test_predictions})\n","    \n","    # feature importance dataframe\n","    feature_importances = pd.DataFrame({'feature' : features_name, 'importance' : feature_importance_values})\n","    \n","    # overall validation score\n","    valid_auc = roc_auc_score(labels, out_of_fold)\n","    \n","    # add the overall scores to metrics\n","    valid_scores.append(valid_auc)\n","    train_scores.append(np.mean(train_scores))\n","    \n","    fold_names = list(range(n_folds))\n","    fold_names.append('overall')\n","    \n","    metrics = pd.DataFrame({'fold' : fold_names, 'train' : train_scores, 'valid' : valid_scores})\n","    \n","    return submission, feature_importances, metrics"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:26:58.790019Z","iopub.status.busy":"2021-12-29T07:26:58.789303Z","iopub.status.idle":"2021-12-29T07:30:19.451354Z","shell.execute_reply":"2021-12-29T07:30:19.450382Z","shell.execute_reply.started":"2021-12-29T07:26:58.789949Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["training data shape :  (307511, 238)\n","test data shape :  (48744, 238)\n","Training until validation scores don't improve for 100 rounds\n","[200]\ttrain's auc: 0.797263\ttrain's binary_logloss: 0.549253\tvalid's auc: 0.754613\tvalid's binary_logloss: 0.564614\n","Early stopping, best iteration is:\n","[279]\ttrain's auc: 0.80977\ttrain's binary_logloss: 0.537089\tvalid's auc: 0.755213\tvalid's binary_logloss: 0.556854\n","Training until validation scores don't improve for 100 rounds\n","[200]\ttrain's auc: 0.797071\ttrain's binary_logloss: 0.54948\tvalid's auc: 0.75653\tvalid's binary_logloss: 0.565188\n","Early stopping, best iteration is:\n","[225]\ttrain's auc: 0.801202\ttrain's binary_logloss: 0.545443\tvalid's auc: 0.756755\tvalid's binary_logloss: 0.562718\n","Training until validation scores don't improve for 100 rounds\n","[200]\ttrain's auc: 0.796361\ttrain's binary_logloss: 0.550805\tvalid's auc: 0.762559\tvalid's binary_logloss: 0.565105\n","Early stopping, best iteration is:\n","[245]\ttrain's auc: 0.803671\ttrain's binary_logloss: 0.543801\tvalid's auc: 0.762891\tvalid's binary_logloss: 0.560708\n","Training until validation scores don't improve for 100 rounds\n","[200]\ttrain's auc: 0.797467\ttrain's binary_logloss: 0.549394\tvalid's auc: 0.757258\tvalid's binary_logloss: 0.563246\n","Early stopping, best iteration is:\n","[235]\ttrain's auc: 0.803343\ttrain's binary_logloss: 0.543631\tvalid's auc: 0.757525\tvalid's binary_logloss: 0.559636\n","Training until validation scores don't improve for 100 rounds\n","[200]\ttrain's auc: 0.796607\ttrain's binary_logloss: 0.549996\tvalid's auc: 0.75605\tvalid's binary_logloss: 0.566233\n","Early stopping, best iteration is:\n","[262]\ttrain's auc: 0.806412\ttrain's binary_logloss: 0.540566\tvalid's auc: 0.756298\tvalid's binary_logloss: 0.560435\n","      fold     train     valid\n","0        0  0.809770  0.755213\n","1        1  0.801202  0.756755\n","2        2  0.803671  0.762891\n","3        3  0.803343  0.757525\n","4        4  0.806412  0.756298\n","5  overall  0.804879  0.757731\n"]}],"source":["submission, feature_importances, metrics = model(train, test)\n","print(metrics)"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:40:40.537953Z","iopub.status.busy":"2021-12-29T07:40:40.537078Z","iopub.status.idle":"2021-12-29T07:40:40.782575Z","shell.execute_reply":"2021-12-29T07:40:40.781798Z","shell.execute_reply.started":"2021-12-29T07:40:40.537912Z"},"trusted":true},"outputs":[],"source":["# fi_sorted = plot_feature_importances(feature_importances)"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:41:19.900577Z","iopub.status.busy":"2021-12-29T07:41:19.900328Z","iopub.status.idle":"2021-12-29T07:41:19.905397Z","shell.execute_reply":"2021-12-29T07:41:19.904469Z","shell.execute_reply.started":"2021-12-29T07:41:19.900552Z"},"trusted":true},"outputs":[],"source":["# submission.to_csv('baseline_lgb.csv', index = False)"]},{"cell_type":"markdown","metadata":{},"source":["This submission should **score about 0.735** on the leaderboard. We will certainly best that in future work!\n","\n"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:48:36.056938Z","iopub.status.busy":"2021-12-29T07:48:36.056693Z","iopub.status.idle":"2021-12-29T07:51:44.966370Z","shell.execute_reply":"2021-12-29T07:51:44.965736Z","shell.execute_reply.started":"2021-12-29T07:48:36.056914Z"},"trusted":true},"outputs":[],"source":["# train_domain['TARGET'] = train_labels\n","\n","# submission_domain, fi_domain, metrics_domain = model(train_domain, test_domain)\n","# print(metrics_domain)"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:51:44.968632Z","iopub.status.busy":"2021-12-29T07:51:44.967752Z","iopub.status.idle":"2021-12-29T07:51:45.190552Z","shell.execute_reply":"2021-12-29T07:51:45.189678Z","shell.execute_reply.started":"2021-12-29T07:51:44.968595Z"},"trusted":true},"outputs":[],"source":["# fi_sorted = plot_feature_importances(fi_domain)"]},{"cell_type":"markdown","metadata":{},"source":["Again, we see tha some of our features made it into the most important. Going forward, we will need to think about whatother domain knowledge features may be useful for this problem (or we should consult someone who knows more about the financial industry!"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2021-12-29T07:51:45.191937Z","iopub.status.busy":"2021-12-29T07:51:45.191729Z","iopub.status.idle":"2021-12-29T07:51:45.196942Z","shell.execute_reply":"2021-12-29T07:51:45.195819Z","shell.execute_reply.started":"2021-12-29T07:51:45.191909Z"},"trusted":true},"outputs":[],"source":["# submission_domain.to_csv('baseline_lgb_domain_features.csv', index = False)"]},{"cell_type":"markdown","metadata":{},"source":["This model **scores about 0.754** when submitted to the public leaderboard indicating that the domain features do improve the performance! Feature engineering is going to be a critical part of this competition (as it is for all machine learning problems)!"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[],"source":["# xgboost로 구현해보기\n","\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import roc_auc_score\n","import xgboost as xgb\n","import gc\n","\n","def xgbmodel(features, test_features, encoding = 'ohe', n_folds=5) :\n","    train_ids = features['SK_ID_CURR']\n","    test_ids = test_features['SK_ID_CURR']\n","    \n","    labels = features['TARGET']\n","    \n","    features = features.drop(columns=['SK_ID_CURR','TARGET'])\n","    test_features = test_features.drop(columns=['SK_ID_CURR'])\n","    \n","    # One-Hot encoding\n","    if encoding == 'ohe' :\n","        features = pd.get_dummies(features)\n","        test_features = pd.get_dummies(test_features)\n","        \n","        # align the dataframe\n","        features, test_features = features.align(test_features, join='inner', axis=1)\n","        \n","        cat_indices = 'auto'\n","    \n","    # Label encoding\n","    elif encoding == 'le' :\n","        label_encoder = LabelEncoder()\n","        \n","        # list for storing categorical indices\n","        cat_indices = []\n","        \n","        for i, col in enumerate(features) :\n","            if features[col].dtype == 'object' :\n","                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n","                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n","                \n","                # record the categorical indices\n","                cat_indices.append(i)\n","    \n","    else :\n","        raise ValueError(\"encoding must be either 'ohe' or 'le'\")\n","        \n","    print('training data shape : ', features.shape)\n","    print('test data shape : ', test_features.shape)\n","    \n","    features_name = list(features.columns)\n","    \n","    features = np.array(features)\n","    test_features = np.array(test_features)\n","    \n","    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n","    \n","    feature_importance_values = np.zeros(len(features_name))\n","    \n","    test_predictions = np.zeros(test_features.shape[0])\n","    \n","    out_of_fold = np.zeros(features.shape[0])\n","    \n","    valid_scores = []\n","    train_scores = []\n","    \n","    for train_indices, valid_indices in k_fold.split(features) :\n","        # training, validation data \n","        train_features, train_labels = features[train_indices], labels[train_indices]\n","        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n","        \n","        # create model\n","        model = xgb.XGBClassifier(n_estimators =10000, objective = 'binary:logistic', learning_rate = 0.05,\n","                                   reg_alpha = 0.1, reg_lambda = 0.1, subsample = 0.8, n_jobs=-1, random_state = 50)\n","        # train model\n","        model.fit(train_features, train_labels, eval_metric = 'auc', \n","                  eval_set = [(valid_features,valid_labels),(train_features,train_labels)], early_stopping_rounds = 100, verbose=200)\n","        \n","        # record best iteration\n","        best_iteration = model.best_iteration\n","        \n","        # record the feature importances\n","        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n","        \n","        # make prediction\n","        test_predictions += model.predict_proba(test_features, num_interation = best_iteration)[:, 1] / k_fold.n_splits\n","        \n","        # record the out of fold predictions\n","        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:,1]\n","        \n","        # record the best score\n","        valid_score = model.best_score_['valid']['auc']\n","        train_score = model.best_score_['train']['auc']\n","        \n","        valid_scores.append(valid_score)\n","        train_scores.append(train_score)\n","        \n","        # clean up memory\n","        gc.enable()\n","        del model, train_features, valid_features\n","        gc.collect()\n","        \n","    # make submission \n","    submission = pd.DataFrame({'SK_ID_CURR' : test_ids, 'TARGET' : test_predictions})\n","    \n","    # feature importance dataframe\n","    feature_importances = pd.DataFrame({'feature' : features_name, 'importance' : feature_importance_values})\n","    \n","    # overall validation score\n","    valid_auc = roc_auc_score(labels, out_of_fold)\n","    \n","    # add the overall scores to metrics\n","    valid_scores.append(valid_auc)\n","    train_scores.append(np.mean(train_scores))\n","    \n","    fold_names = list(range(n_folds))\n","    fold_names.append('overall')\n","    \n","    metrics = pd.DataFrame({'fold' : fold_names, 'train' : train_scores, 'valid' : valid_scores})\n","    \n","    return submission, feature_importances, metrics"]},{"cell_type":"code","execution_count":114,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["training data shape :  (307511, 238)\n","test data shape :  (48744, 238)\n","[0]\tvalidation_0-auc:0.71074\tvalidation_1-auc:0.72111\n","[200]\tvalidation_0-auc:0.75361\tvalidation_1-auc:0.80962\n","[400]\tvalidation_0-auc:0.75567\tvalidation_1-auc:0.84364\n","[600]\tvalidation_0-auc:0.75531\tvalidation_1-auc:0.86911\n","[800]\tvalidation_0-auc:0.75428\tvalidation_1-auc:0.89004\n","[1000]\tvalidation_0-auc:0.75282\tvalidation_1-auc:0.90759\n","[1200]\tvalidation_0-auc:0.75205\tvalidation_1-auc:0.92291\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-114-3b6171944c5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msubmission_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_importances_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgbmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics_xgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-113-7d019460a0ab>\u001b[0m in \u001b[0;36mxgbmodel\u001b[1;34m(features, test_features, encoding, n_folds)\u001b[0m\n\u001b[0;32m     69\u001b[0m                                    reg_alpha = 0.1, reg_lambda = 0.1, subsample = 0.8, n_jobs=-1, random_state = 50)\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         model.fit(train_features, train_labels, eval_metric = 'auc', \n\u001b[0m\u001b[0;32m     72\u001b[0m                   eval_set = [(valid_features,valid_labels),(train_features,train_labels)], early_stopping_rounds = 100, verbose=200)\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1248\u001b[0m         )\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m   1251\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m--> 188\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    189\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1680\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1682\u001b[0m                                                     dtrain.handle))\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["submission_xgb, feature_importances_xgb, metrics_xgb = xgbmodel(train, test)\n","print(metrics_xgb)"]},{"cell_type":"markdown","metadata":{},"source":["xgboost training시 overfitting 문제 생김 : \n","\n","[0]\tvalidation_0-auc:0.71074\tvalidation_1-auc:0.72111\n","\n","[200]\tvalidation_0-auc:0.75361\tvalidation_1-auc:0.80962\n","\n","[400]\tvalidation_0-auc:0.75567\tvalidation_1-auc:0.84364\n","\n","[600]\tvalidation_0-auc:0.75531\tvalidation_1-auc:0.86911\n","\n","[800]\tvalidation_0-auc:0.75428\tvalidation_1-auc:0.89004\n","\n","[1000]\tvalidation_0-auc:0.75282\tvalidation_1-auc:0.90759\n","\n","[1200]\tvalidation_0-auc:0.75205\tvalidation_1-auc:0.92291\n","\n","시간도 오래걸림 여기까지가 5m 40s, \n","\n","lgb는 다 끝나는 시간이 1m 16s "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
